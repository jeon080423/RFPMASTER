import streamlit as st
import pdfplumber
import pandas as pd
import re
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
import datetime
import time
import google.generativeai as genai
import traceback
import auth
import email_utils

# -----------------------------------------------------------------------------
# 1. Config & Branding
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ìˆ˜ì£¼ë¹„ì±… - RFP ë¶„ì„ ì†”ë£¨ì…˜",
    page_icon="favicon.png",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem; font-weight: 800; text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.1rem; text-align: center; color: #888;
        margin-bottom: 1.5rem;
    }
    .footer {
        text-align: center; color: #aaa; font-size: 0.85rem;
        margin-top: 3rem; padding: 1rem 0;
        border-top: 1px solid #eee;
    }
    /* Sidebar login styling */
    .sidebar-login-header {
        font-size: 1.1rem; font-weight: 700; margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. Authentication (Sidebar)
# -----------------------------------------------------------------------------
try:
    auth.init_db()
except Exception as e:
    st.error(f"âš ï¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

if "user" not in st.session_state:
    st.session_state.user = None

# --- Sidebar ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2921/2921222.png", width=50)
    
    if st.session_state.user:
        # --- Logged-in state ---
        st.success(f"ğŸ‘¤ **{st.session_state.user['name']}**ë‹˜ ì ‘ì† ì¤‘")
        
        if not st.session_state.user.get('approved', False):
            st.warning("â³ ê³„ì • ìŠ¹ì¸ ëŒ€ê¸° ì¤‘")
        
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_sidebar", use_container_width=True):
            st.session_state.user = None
            st.rerun()
        
        # --- Change Password flow ---
        with st.expander("ğŸ› ï¸ ë¹„ë°€ë²ˆí˜¸ ë³€ê²½"):
            new_pw_settings = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸", type="password", key="settings_new_pw")
            confirm_pw_settings = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="settings_new_pw_chk")
            if st.button("ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ì ìš©", use_container_width=True):
                if new_pw_settings and new_pw_settings == confirm_pw_settings:
                    if auth.update_password(st.session_state.user['email'], new_pw_settings):
                        st.success("ë¹„ë°€ë²ˆí˜¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # Admin Logic
        if st.session_state.user.get('role') == 'admin':
            st.markdown("---")
            st.subheader("ğŸ‘‘ ê´€ë¦¬ì ë©”ë‰´")
            pending_users = auth.get_pending_users()
            if not pending_users.empty:
                st.warning(f"ìŠ¹ì¸ ëŒ€ê¸°: {len(pending_users)}ëª…")
                for _, row in pending_users.iterrows():
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"**{row['name']}** ({row['email']})")
                    with col2:
                        if st.button("ìŠ¹ì¸", key=f"btn_{row['email']}"):
                            auth.approve_user(row['email'])
                            success, form = email_utils.send_approval_email(row['email'])
                            if success:
                                st.success(f"ìŠ¹ì¸ ì™„ë£Œ!")
                            else:
                                st.warning(f"ìŠ¹ì¸ ì™„ë£Œ, ë©”ì¼ ì‹¤íŒ¨")
                            st.rerun()
            else:
                st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ íšŒì› ì—†ìŒ")
            
            st.markdown("---")
            st.subheader("ğŸ“Š ì‚¬ìš©ì í™œë™ í˜„í™©")
            all_users = auth.get_all_users()
            if not all_users.empty:
                # Clean up display (email, name, role, last_login, analysis_count)
                display_df = all_users[['name', 'email', 'role', 'last_login', 'analysis_count']].copy()
                display_df.columns = ['ì´ë¦„/ë‹‰ë„¤ì„', 'ì´ë©”ì¼', 'êµ¬ë¶„', 'ìµœì¢…ë¡œê·¸ì¸', 'ì‚¬ìš©íšŸìˆ˜']
                st.dataframe(display_df, use_container_width=True, hide_index=True)
            else:
                st.info("ë“±ë¡ëœ ì‚¬ìš©ì ì—†ìŒ")

            st.markdown("---")
            with st.expander("ğŸ› ï¸ ê´€ë¦¬ì ì„¤ì •", expanded=True):
                # Cleaned up model options: removing 2.5 (beta/exp) and old versions if necessary
                # Keeping stable and high-perf models
                model_options = [
                    "ìë™ ìµœì í™” (ê¶Œì¥)", 
                    "gemini-2.0-pro-exp-02-05", 
                    "gemini-2.0-flash", 
                    "gemini-1.5-pro", 
                    "gemini-1.5-flash", 
                    "groq-openai-gpt-oss-120b",
                    "groq-llama-4-preview",
                    "groq-llama-3.3-70b",
                    "groq-qwen3-32b"
                ]
                
                # Model selection for the Admin themselves
                st.selectbox(
                    "ê´€ë¦¬ì ì „ìš© ëª¨ë¸ ì§€ì •", 
                    options=model_options, 
                    key="admin_selected_model",
                    help="í˜„ì¬ ì„¸ì…˜ì—ì„œ ê´€ë¦¬ì ë³¸ì¸ì´ ì‚¬ìš©í•  ëª¨ë¸ì„ ê³ ë¦…ë‹ˆë‹¤."
                )

                # Global model setting for regular users
                current_global_default = auth.get_global_setting("user_default_model", "gemini-2.5-flash")
                # Find index of current setting in options
                try: 
                    default_idx = model_options.index(current_global_default)
                except: 
                    default_idx = 2 # Default to 2.5 flash if not found

                new_global_default = st.selectbox(
                    "ğŸŒŸ ì¼ë°˜ ì‚¬ìš©ì ê¸°ë³¸ ëª¨ë¸ ì„¤ì •",
                    options=model_options,
                    index=default_idx,
                    help="ëª¨ë“  ì¼ë°˜ ì‚¬ìš©ìê°€ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê²Œ ë  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤. (ì‹¤ì‹œê°„ ë°˜ì˜)"
                )
                
                if new_global_default != current_global_default:
                    if auth.set_global_setting("user_default_model", new_global_default):
                        st.success(f"ê¸°ë³¸ ëª¨ë¸ì´ {new_global_default}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.cache_data.clear() # Clear cache to reflect change
    else:
        # --- Not logged-in state ---
        st.markdown('<div class="sidebar-login-header">ğŸ” ë¡œê·¸ì¸</div>', unsafe_allow_html=True)
        
        login_tab, signup_tab = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"])
        
        with login_tab:
            email = st.text_input("ì´ë©”ì¼", key="login_email")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")
            if st.button("ë¡œê·¸ì¸", type="primary", use_container_width=True):
                user = auth.login_user(email, password)
                if user:
                    st.session_state.user = user
                    st.rerun()
                else:
                    st.error("ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # Forgot Password Logic
            with st.expander("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ë¥¼ ìŠìœ¼ì…¨ë‚˜ìš”?"):
                reset_email = st.text_input("ê°€ì…í•œ ì´ë©”ì¼ì„ ì…ë ¥í•˜ì„¸ìš”", key="reset_email_input")
                if st.button("ì„ì‹œ ë¹„ë°€ë²ˆí˜¸ ë°œê¸‰", use_container_width=True):
                    if reset_email:
                        new_pw = auth.reset_password(reset_email)
                        if new_pw:
                            success, msg = email_utils.send_password_reset_email(reset_email, new_pw)
                            if success:
                                st.success("ì„ì‹œ ë¹„ë°€ë²ˆí˜¸ê°€ ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            else:
                                st.error(f"ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {msg}")
                        else:
                            st.error("í•´ë‹¹ ì´ë©”ì¼ë¡œ ê°€ì…ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ì´ë©”ì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        with signup_tab:
            new_email = st.text_input("ì´ë©”ì¼", key="signup_email")
            new_name = st.text_input("ì´ë¦„ ë˜ëŠ” ë‹‰ë„¤ì„", key="signup_name")
            new_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="signup_pw")
            st.caption("ğŸ”’ ë¹„ë°€ë²ˆí˜¸ëŠ” ì•”í˜¸í™”ë˜ì–´ ì‹¤ì‹œê°„ ë³´ì•ˆ ì €ì¥ë©ë‹ˆë‹¤.")
            new_password_confirm = st.text_input("ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="signup_pw_chk")
            
            if st.button("ê°€ì…í•˜ê¸°", use_container_width=True):
                if new_password != new_password_confirm:
                    st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                elif not new_email or not new_password or not new_name:
                    st.error("ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    if auth.create_user(new_email, new_password, new_name):
                        email_utils.send_admin_notification(new_email, new_name)
                        st.success("ê°€ì… ìš”ì²­ ì™„ë£Œ! ê´€ë¦¬ì ìŠ¹ì¸ í›„ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    else:
                        st.error("ì´ë¯¸ ê°€ì…ëœ ì´ë©”ì¼ì…ë‹ˆë‹¤.")
    
    # Settings (Multi-key support)
    st.markdown("---")
    sec_gemini = st.secrets.get("gemini", {})
    api_keys = []
    
    # Dynamically collect all keys starting with 'api_key'
    try:
        # Streamlit secrets might not be a literal dict, but should be iterable
        sorted_keys = sorted(sec_gemini.keys())
        for k in sorted_keys:
            if k.startswith("api_key") and sec_gemini[k]:
                api_keys.append(sec_gemini[k])
    except:
        # Fallback for unexpected secrets structure
        if sec_gemini.get("api_key"): 
            api_keys.append(sec_gemini.get("api_key"))
    
    # Fallback to env if empty
    if not api_keys and os.environ.get("GOOGLE_API_KEY"):
        api_keys.append(os.environ.get("GOOGLE_API_KEY"))
    
    # Current primary key for simple usage
    api_key = api_keys[0] if api_keys else ""
    
    # Groq API Key
    groq_api_key = st.secrets.get("groq", {}).get("api_key", os.environ.get("GROQ_API_KEY", ""))
    
    st.markdown("---")
    st.markdown("**Developed by ã…ˆã……ã…**")
    st.markdown("""
    <div style='
        font-size: 0.95rem; 
        color: white; 
        background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%); 
        padding: 20px; 
        border-radius: 12px; 
        margin-top: 15px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        line-height: 1.6;
    '>
        <div style='font-weight: 800; font-size: 1.1rem; margin-bottom: 12px; border-bottom: 1px solid rgba(255,255,255,0.3); padding-bottom: 5px;'>
            Developer Contact
        </div>
        <div style='margin-bottom: 8px;'>
            <b>ì´ë©”ì¼</b><br>jeon080423@gmail.com
        </div>
        <div style='margin-bottom: 12px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;'>
            <b>í›„ì›ê³„ì¢Œ</b><br>
            <span style='font-size: 0.9rem;'>ì¹´ì¹´ì˜¤ë±…í¬ 3333-23-866708 ã…ˆã……ã…</span>
        </div>
        <div style='font-size: 0.8rem; background: rgba(0,0,0,0.15); padding: 10px; border-radius: 8px; font-weight: 500;'>
            ì§€ì† ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•´ ì—¬ëŸ¬ë¶„ì˜ ì‘ì›ì´ í•„ìš”í•©ë‹ˆë‹¤. ëª¨ì¸ í›„ì›ê¸ˆì€ ì„œë²„ ë¹„ìš© ë° API ì—…ê·¸ë ˆì´ë“œë¥¼ ìœ„í•œ ìê¸ˆìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        </div>
    </div>
    """, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 3. Utility Functions
# -----------------------------------------------------------------------------
def mask_pii(text):
    rrn_pattern = r'\d{6}[-\s]\d{7}'
    masked_text = re.sub(rrn_pattern, '******-*******', text)
    return masked_text

def remove_repeating_lines(pages_text_list):
    """Detects and removes frequent headers/footers appearing at top/bottom of pages."""
    if len(pages_text_list) < 3: return pages_text_list # Too few pages to identify patterns
    
    header_counts = {}
    footer_counts = {}
    
    for page in pages_text_list:
        lines = [l.strip() for l in page.split('\n') if l.strip()]
        if not lines: continue
        
        h = lines[0]
        f = lines[-1]
        
        header_counts[h] = header_counts.get(h, 0) + 1
        footer_counts[f] = footer_counts.get(f, 0) + 1
    
    # Threshold: line appears in more than 50% of pages
    threshold = len(pages_text_list) * 0.5
    headers_to_remove = {k for k, v in header_counts.items() if v > threshold}
    footers_to_remove = {k for k, v in footer_counts.items() if v > threshold}
    
    cleaned_pages = []
    for page in pages_text_list:
        lines = page.split('\n')
        if not lines:
            cleaned_pages.append("")
            continue
            
        new_lines = []
        for i, line in enumerate(lines):
            ls = line.strip()
            # Remove if it's the first/last non-empty line and in removal set
            if i == 0 and ls in headers_to_remove: continue
            if i == len(lines)-1 and ls in footers_to_remove: continue
            new_lines.append(line)
        cleaned_pages.append('\n'.join(new_lines))
        
    return cleaned_pages

def extract_text_from_pdf(uploaded_file):
    if not uploaded_file: return ""
    
    # --- Extraction Caching ---
    file_id = f"{uploaded_file.name}_{uploaded_file.size}"
    if "extraction_cache" not in st.session_state:
        st.session_state.extraction_cache = {}
        
    if file_id in st.session_state.extraction_cache:
        return st.session_state.extraction_cache[file_id]
    
    text = ""
    boilerplate_keywords = ["ì²­ë ´ê³„ì•½", "ì„œì‹ ì œ", "ë³„ì§€ ì œ", "ì¡°ì„¸í¬íƒˆ", "ì²­ë ´ ì„œì•½", "í–‰ì • ì²˜ë¶„", "ì…ì°° ì°¸ê°€ ì‹ ì²­ì„œ"]
    preserve_keywords = ["ì œì¶œ ì„œë¥˜", "ì„œë¥˜ ëª©ë¡", "í‰ê°€í•­ëª©", "ë°°ì í‘œ"]
    
    filtered_pages = 0
    pages_text_list = []
    
    try:
        with pdfplumber.open(uploaded_file) as pdf:
            total_pages = len(pdf.pages)
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    # Logic: If boilerplate keyword exists, check if any preserve keyword exists
                    # If it's pure boilerplate (forms/stamps), skip it to save tokens
                    has_bp = any(kw in page_text for kw in boilerplate_keywords)
                    has_pr = any(kw in page_text for kw in preserve_keywords)
                    
                    if has_bp and not has_pr:
                        filtered_pages += 1
                        continue # Skip this page
                    
                    # Prepend explicit Page Marker for accurate citations despite H/F removal
                    page_with_marker = f"[Page {page.page_number}]\n{page_text}"
                    pages_text_list.append(page_with_marker)
        
        # --- Advanced Optimization: Header/Footer Removal ---
        cleaned_pages = remove_repeating_lines(pages_text_list)
        text = "\n".join(cleaned_pages)
        
        # --- Token Saving Cleanup ---
        # Remove redundant newlines (3 or more -> 2)
        text = re.sub(r'\n{3,}', '\n\n', text)
        # Remove redundant spaces (2 or more -> 1)
        text = re.sub(r' +', ' ', text)
        # Structural Optimization: Collapse | | spaces in potential tables
        text = re.sub(r'\|\s+\|', '||', text)
        # Remove leading/trailing whitespace per line
        text = '\n'.join([line.strip() for line in text.split('\n')])
        
        if filtered_pages > 0:
            st.info(f"ğŸ’¡ í–‰ì • ì„œì‹ ë° ë‹¨ìˆœ ì–‘ì‹ í˜ì´ì§€ {filtered_pages}ê°œë¥¼ ë¶„ì„ì—ì„œ ì œì™¸í•˜ì—¬ í† í°ì„ ì ˆì•½í–ˆìŠµë‹ˆë‹¤. (ì „ì²´ {total_pages}p)")
        
        # Mask PII and Cache
        final_text = mask_pii(text)
        st.session_state.extraction_cache[file_id] = final_text
        return final_text
        
    except Exception as e:
        return f"Error reading PDF: {e}"

def get_best_available_model(api_key):
    """Dynamically find the best available model (Pro first) for the given API key."""
    if "model_cache" not in st.session_state:
        st.session_state.model_cache = {}
        
    try:
        # Check cache first to save quota calls
        if api_key in st.session_state.model_cache:
            available_models = st.session_state.model_cache[api_key]
        else:
            genai.configure(api_key=api_key)
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.session_state.model_cache[api_key] = available_models
        
        priority = [
            "models/gemini-2.5-pro",
            "models/gemini-2.5-flash",
            "models/gemini-2.0-pro-exp",
            "models/gemini-2.0-flash",
            "models/gemini-1.5-pro",
            "models/gemini-1.5-pro-latest",
            "models/gemini-1.5-flash",
            "models/gemini-pro"
        ]
        
        for p in priority:
            if p in available_models:
                return p.split("/")[-1]
        
        if available_models:
            return available_models[0].split("/")[-1]
    except: pass
    return "gemini-1.5-flash"

def get_flash_model(api_key):
    """Dynamically find the fastest/cheapest available model (Flash first)."""
    if "model_cache" not in st.session_state:
        st.session_state.model_cache = {}

    try:
        # Check cache first to save quota calls
        if api_key in st.session_state.model_cache:
            available_models = st.session_state.model_cache[api_key]
        else:
            genai.configure(api_key=api_key)
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.session_state.model_cache[api_key] = available_models
        
        # Priority: Flash 2.5 -> Flash 2.0 -> Flash 1.5
        priority = [
            "models/gemini-2.5-flash",
            "models/gemini-2.0-flash",
            "models/gemini-1.5-flash",
            "models/gemini-1.5-flash-latest",
            "models/gemini-1.5-pro"
        ]
        
        for p in priority:
            if p in available_models:
                return p.split("/")[-1]
    except: pass
    return "gemini-1.5-flash"

def get_relevant_context(text, keywords, box_size=2000, max_len=4000):
    """Extracts relevant text chunks around keywords. Sizes reduced for Groq TPM limit."""
    relevant_chunks = []
    text_lower = text.lower()
    for kw in keywords:
        start_idx = 0
        while True:
            idx = text_lower.find(kw, start_idx)
            if idx == -1: break
            start = max(0, idx - 500)
            end = min(len(text), idx + box_size)
            chunk = text[start:end]
            relevant_chunks.append(chunk)
            start_idx = idx + len(kw)
    if not relevant_chunks:
        return text[:max_len]
    combined = "\n...\n".join(relevant_chunks)
    return combined[:max_len]

# -----------------------------------------------------------------------------
# 4. Main Content (Always visible)
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# Global Quota Status Notification
# -----------------------------------------------------------------------------
is_exhausted, reset_time = auth.check_quota_status()
if is_exhausted:
    st.warning(f"âš ï¸ **ê¸ˆì¼ ëª¨ë“  ë¶„ì„ API ì¿¼í„°ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.**\n\nëª¨ë“  ì˜ˆë¹„ ì—”ì§„(Gemini, Groq)ì˜ ì¼ì¼ í• ë‹¹ëŸ‰ì´ ëª¨ë‘ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì´ˆê¸°í™” ì‹œê°„(**{reset_time} KST**) ì´í›„ì— ë‹¤ì‹œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

st.markdown('<div class="main-header">ìˆ˜ì£¼ë¹„ì±… (Win Strategy)</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ê³µê³µê¸°ê´€ ì…ì°° ì„±ê³µì„ ìœ„í•œ ì œì•ˆìš”ì²­ì„œ(RFP) ì‹¬ì¸µ ë¶„ì„ ì†”ë£¨ì…˜</div>', unsafe_allow_html=True)

# Rate limit retry helper with Key Rotation & Groq Fallback
def invoke_with_retry(prompt_template, params, api_keys, groq_api_key=None, use_flash=False, model_name=None):
    """Invoke LLM chain with Gemini keys (once each) and then Groq fallback."""
    if not api_keys:
        raise Exception("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # --- Try Groq FIRST if explicitly selected ---
    if model_name and model_name.startswith("groq-") and groq_api_key:
        try:
            groq_model = model_name.replace("groq-", "")
            # Mapping short IDs and legacy IDs to actual current Groq model strings (verified Feb 2026)
            mapping = {
                "openai-gpt-oss-120b": "openai/gpt-oss-120b",
                "llama-4-preview": "meta-llama/llama-4-maverick-17b-128e-instruct",
                "llama-3.3-70b": "llama-3.3-70b-versatile",
                "qwen3-32b": "qwen/qwen3-32b",
                # Legacy / Decommissioned redirects
                "deepseek-r1-70b": "llama-3.3-70b-versatile",
                "llama-3.1-70b": "llama-3.3-70b-versatile",
                "gemma2-9b": "llama-3.3-70b-versatile"
            }
            actual_groq_model = mapping.get(groq_model, groq_model)
            
            # Final safety block for decommissioned strings
            decommissioned_keywords = ["llama-3.1", "gemma2", "deepseek-r1-distill-llama"]
            if any(dec in actual_groq_model for dec in decommissioned_keywords):
                actual_groq_model = "llama-3.3-70b-versatile"
            
            llm = ChatGroq(
                temperature=0.0, 
                model_name=actual_groq_model, 
                groq_api_key=groq_api_key
            )
            chain = prompt_template | llm | StrOutputParser()
            return chain.invoke(params)
        except Exception as groq_err:
            st.warning(f"ğŸ”„ Groq ìš°ì„  í˜¸ì¶œ ì‹¤íŒ¨ ({groq_err}). ì œë¯¸ë‚˜ì´ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")

    # Try each Gemini key exactly once
    for i, key in enumerate(api_keys):
        try:
            # If a specific Gemini model was requested, use it, otherwise detect best
            if model_name and model_name.startswith("gemini-"):
                actual_model = model_name
            else:
                actual_model = get_flash_model(key) if use_flash else get_best_available_model(key)
                
            llm = ChatGoogleGenerativeAI(temperature=0.0, model=actual_model, google_api_key=key)
            chain = prompt_template | llm | StrOutputParser()
            return chain.invoke(params)
        except Exception as e:
            error_str = str(e).lower()
            if 'rate_limit' in error_str or '429' in error_str or 'resource_exhausted' in error_str:
                st.warning(f"ğŸ”„ ì œë¯¸ë‚˜ì´ {i + 1}ë²ˆ í‚¤ í•œë„ ì´ˆê³¼. ë‹¤ìŒ í‚¤ë¡œ ì¦‰ì‹œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue # Try the next key in the list
            else:
                raise e
                
    # --- Final Fallback to Groq (Using high-quality production models) ---
    if groq_api_key:
        try:
            st.info("ğŸ’¡ ëª¨ë“  ì œë¯¸ë‚˜ì´ í•œë„ê°€ ì´ˆê³¼ë˜ì–´ ê³ ì„±ëŠ¥ Groq ì—”ì§„(Llama-3.3-70b)ìœ¼ë¡œ ì „í™˜í•˜ì—¬ ë¶„ì„ì„ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.")
            llm = ChatGroq(
                temperature=0.0, 
                model_name="llama-3.3-70b-versatile", 
                groq_api_key=groq_api_key
            )
            chain = prompt_template | llm | StrOutputParser()
            return chain.invoke(params)
        except Exception as groq_err:
            st.error(f"âŒ Groq(DeepSeek-R1) ì—”ì§„ í˜¸ì¶œ ì‹¤íŒ¨: {groq_err}")
            
            # Last resort: Try Llama 3.3 if DeepSeek also fails
            try:
                llm = ChatGroq(temperature=0.0, model_name="llama-3.3-70b-versatile", groq_api_key=groq_api_key)
                chain = prompt_template | llm | StrOutputParser()
                return chain.invoke(params)
            except: pass

    # If we reach here, everything failed.
    auth.record_quota_exhaustion()
    raise Exception("ëª¨ë“  API í‚¤ì˜ í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë³´í†µ í”„ë¡œì íŠ¸ ë‹¨ìœ„ì˜ ë¶„ë‹¹ í† í° ì œí•œ(TPM) ë˜ëŠ” ì¼ì¼ í•œë„(RPD)ì— ë„ë‹¬í–ˆì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤. ì•½ 1ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì˜¤í›„ 5ì‹œ ì´ˆê¸°í™” ì´í›„ ì´ìš©í•´ ì£¼ì„¸ìš”.")

st.info("âš ï¸ ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ëª¨ë“  ë¬¸ì„œëŠ” **PDF í˜•ì‹**ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    st.subheader("1. ê¸ˆë…„ë„ ê³µê³  ìë£Œ (í•„ìˆ˜)")
    st.markdown("<div style='margin-bottom: 28px;'></div>", unsafe_allow_html=True)
    current_rfp = st.file_uploader("ì˜¬í•´ ì œì•ˆìš”ì²­ì„œ ë˜ëŠ” ê³¼ì—…ì§€ì‹œì„œ", type=["pdf"], key="curr_rfp")

with col2:
    st.subheader("2. ì§ì „ íšŒì°¨ ê³µê³  ìë£Œ (ì„ íƒ)")
    st.markdown("<div style='margin-bottom: 28px;'></div>", unsafe_allow_html=True)
    prev_rfp = st.file_uploader("ì§ì „ íšŒì°¨ ì œì•ˆìš”ì²­ì„œ ë˜ëŠ” ê³¼ì—…ì§€ì‹œì„œ", type=["pdf"], key="prev_rfp_uploader")

# --- Conditional: Show analysis button only for logged-in & approved users ---
is_logged_in = st.session_state.user is not None
is_approved = is_logged_in and st.session_state.user.get('approved', False)

if not is_logged_in:
    st.warning("ğŸ”’ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•˜ë ¤ë©´ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ **ë¡œê·¸ì¸**í•´ ì£¼ì„¸ìš”.")
    start_analysis = False
elif not is_approved:
    st.warning("â³ ê³„ì • ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    start_analysis = False
else:
    start_analysis = st.button("ì œì•ˆìš”ì²­ì„œ ë¶„ì„ ì‹œì‘ ğŸš€", type="primary", use_container_width=True)

# -----------------------------------------------------------------------------
# 5. Analysis Logic (only for approved users)
# -----------------------------------------------------------------------------
    def detect_project_name(text):
        """Attempts to extract the project name from the first page of the RFP with robust regex."""
        if not text: return "ë¯¸ì§€ì • ì‚¬ì—…"
        
        # 1. Look for keywords using regex to handle prefixes (1., ê°€., ë“±)
        lines = [l.strip() for l in text[:3000].split('\n') if l.strip()]
        keywords = ["ì‚¬ì—…ëª…", "ê³¼ì—…ëª…", "ìš©ì—­ëª…", "ëª…ì¹­", "í”„ë¡œì íŠ¸ëª…", "ê³µê³ ëª…"]
        
        for i, line in enumerate(lines):
            for kw in keywords:
                # Regex: optional prefix, keyword, optional colon/bracket
                pattern = rf'^(?:[0-9ê°€-í£\d\.]+\s*)?{kw}\s*[:ï¼š\s\]\)]'
                if re.search(pattern, line):
                    # Try to get content after colon
                    if ':' in line: 
                        name = line.split(':', 1)[1].strip()
                        if len(name) > 3: return name
                    elif 'ï¼š' in line:
                        name = line.split('ï¼š', 1)[1].strip()
                        if len(name) > 3: return name
                    
                    # If line ends with keyword, title is likely on the next line
                    if i + 1 < len(lines):
                        next_line = lines[i+1].strip()
                        if len(next_line) > 3: return next_line
        
        # 2. Heuristic fallback: Look for a long line in the first 10 non-empty lines
        # Usually titles are prominent.
        for line in lines[:10]:
            # Guess it's a title if it's long and doesn't look like an address or simple date
            if 15 < len(line) < 100 and not any(x in line for x in ["ì£¼ì†Œ", "ì¼ì‹œ", "ì¼ì", "ì—°ë½ì²˜"]):
                return line
        
        return "ë¯¸ì§€ì • ì‚¬ì—…"

    def detect_year(text, default_label):
        """Attempts to detect the year from the text (e.g., '2024ë…„')."""
        if not text: return default_label
        match = re.search(r'20\d{2}ë…„', text[:3000])
        if match:
            return match.group(0)
        return default_label

    def clean_ai_output(text):
        """
        Forcefully removes <br> tags. 
        Replaces with \n generally, but with '; ' if inside a table line to prevent row breakage.
        """
        if not text: return ""
        lines = text.split('\n')
        cleaned_lines = []
        for line in lines:
            if '|' in line:
                # Inside table row: replace <br> with ; to keep it on one line
                cleaned_line = re.sub(r'<br\s*/?>', '; ', line, flags=re.IGNORECASE)
                cleaned_lines.append(cleaned_line)
            else:
                # Outside table: replace <br> with \n
                cleaned_line = re.sub(r'<br\s*/?>', '\n', line, flags=re.IGNORECASE)
                cleaned_lines.append(cleaned_line)
        
        # Final step for UI: Convert '; ' back to '<br>' for rendering inside tables
        result = '\n'.join(cleaned_lines)
        if '|' in result:
            final_lines = []
            for line in result.split('\n'):
                if '|' in line:
                    final_lines.append(line.replace('; ', '<br>'))
                else:
                    final_lines.append(line)
            return '\n'.join(final_lines)
        return result

    if start_analysis:
        if not api_keys: # Changed from api_key to api_keys
            st.error("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ API Key ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
        if not current_rfp:
            st.error("ì˜¬í•´ ì œì•ˆìš”ì²­ì„œëŠ” í•„ìˆ˜ ì—…ë¡œë“œ í•­ëª©ì…ë‹ˆë‹¤.")
            st.stop()

        # Clear old results for new analysis
        st.session_state.analysis_results = {}

        auth.increment_analysis_count(st.session_state.user['email'])

        with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            full_current_text = extract_text_from_pdf(current_rfp)
            
            prev_text = ""
            if prev_rfp:
                prev_text = extract_text_from_pdf(prev_rfp)

        # Detect Years
        curr_year = detect_year(full_current_text, "ê¸ˆë…„")
        prev_year = detect_year(prev_text, "ì§ì „") if prev_text else "ì—†ìŒ"

        # --- Diagnostics for user ---
        curr_len = len(full_current_text.strip())
        prev_len = len(prev_text.strip()) if prev_text else 0

        if curr_len < 200:
            st.error(f"âš ï¸ **ê¸ˆë…„ë„ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶€ì¡± (í˜„ì¬ {curr_len}ì)**")
            st.info("ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê±°ì˜ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ PDFì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            st.stop()
        else:
            prev_msg = f" & ì§ì „ ì—°ë„ {prev_len}ì" if prev_len > 0 else ""
            st.success(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! (ê¸ˆë…„ë„ {curr_len}ì{prev_msg})")

        # 1. Resolve Model
        admin_model = st.session_state.get("admin_selected_model")
        is_manual = admin_model and admin_model != "ìë™ ìµœì í™” (ê¶Œì¥)"
        
        if is_manual:
            MODEL_NAME = admin_model
            model_display = f"{MODEL_NAME} (ì‚¬ìš©ì ì§€ì •)"
        else:
            # Load global default set by admin (cached for 10 mins)
            @st.cache_data(ttl=600)
            def fetch_default_model():
                return auth.get_global_setting("user_default_model", "gemini-2.5-flash")
            
            global_model = fetch_default_model()
            MODEL_NAME = global_model
            model_display = f"{MODEL_NAME} (ê´€ë¦¬ì ì§€ì • ê¸°ë³¸ê°’)"
        
        st.info(f"âœ¨ ë¶„ì„ ëª¨ë¸: `{model_display}`")

        try:
            has_prev = bool(prev_text.strip())
            
            # Section 1 ALWAYS appears now. AI handles empty prev info.
            col1_header = "ì´ë²ˆ íšŒì°¨"
            col2_header = "ì§ì „ íšŒì°¨" if prev_text.strip() else "ì§ì „ ìë£Œ ì—†ìŒ"
            
            section_1_prompt = f"""
## 1. ì œì•ˆìš”ì²­ì„œ í•µì‹¬ ë¹„êµ ë° ì „ëµ (RFP Analysis)
*ê¸ˆë…„ë„ì™€ ì§ì „ ì •ë³´ë¥¼ ë¹„êµë¶„ì„í•˜ì„¸ìš”. ì§ì „ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° í•´ë‹¹ ì¹¸ì€ 'ì •ë³´ ì—†ìŒ'ìœ¼ë¡œ ê¸°ì…í•˜ì„¸ìš”.*

| êµ¬ë¶„ | {col1_header} | {col2_header} | ë³€ê²½ ë‚´ìš© ë° ì „ëµì  í•´ì„¤ |
| :-- | :--- | :--- | :--- |
| **ì‚¬ì—… ì˜ˆì‚° ë° ê¸°ê°„** | | | |
| **ëª¨ì§‘ë‹¨** | | | |
| **í‘œë³¸í‹€** | | | |
| **í‘œë³¸í• ë‹¹ë°©ë²•** | | | |
| **ì¡°ì‚¬ì§€ì—­** | | | |
| **í‘œë³¸ìˆ˜** | | | |
| **ì¡°ì‚¬ë°©ë²•(ì˜¨ë¼ì¸/ë©´ì ‘ ë“±)** | | | |
| **í’ˆì§ˆ ë° ê²€ì¦ ê´€ë¦¬** | | | |
| **í•„ìˆ˜ ì¸ë ¥ ìš”ê±´** | | | |
| **ì„±ê³¼í’ˆ ë° í™œìš©** | | | |
"""

            sys_prompt = f"""
# Role Definition
ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ì „ëµ ì»¨ì„¤í„´íŠ¸ì´ì 20ë…„ ê²½ë ¥ì˜ ìˆ˜ì„ ë¦¬ì„œì¹˜ ì—°êµ¬ì›ì…ë‹ˆë‹¤. 
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì ˆëŒ€ì ìœ¼ë¡œ ì œê³µëœ [ê¸ˆë…„ë„ ë¬¸ì„œ]ì˜ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# [CRITICAL RULE] NO HALLUCINATIONS & TABLE STABILITY
1. **ì ˆëŒ€ë¡œ** ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
2. ì •ë³´ê°€ ì—†ëŠ” í•­ëª©ì€ ë°˜ë“œì‹œ **"ëª…ì‹œë˜ì§€ ì•ŠìŒ"** ë˜ëŠ” **"í™•ì¸ ë¶ˆê°€"**ë¼ê³  ì‘ì„±í•˜ì„¸ìš”.
3. **[í‘œ(Table) ì‘ì„± ê·œì¹™]**: ëª¨ë“  í‘œ(Section 1, 2, 3, 4, 5) ë‚´ë¶€ì˜ ê° ì…€ì€ ë°˜ë“œì‹œ **í•œ ì¤„**ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì…€ ë‚´ë¶€ì—ì„œ ë¶ˆë¦¿(`-`)ì´ë‚˜ ì¤„ë°”ê¿ˆì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì¤„ë°”ê¿ˆì´ í•„ìš”í•œ ê²½ìš° ë°˜ë“œì‹œ ì„¸ë¯¸ì½œë¡ (`; `)ì„ ì‚¬ìš©í•˜ì—¬ í•œ ì¤„ë¡œ ë‚˜ì—´í•˜ì„¸ìš”. í‘œì˜ êµ¬ì¡°(`|`)ê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ ê·¹ë„ë¡œ ì£¼ì˜í•˜ì„¸ìš”. í‘œ ì‘ì„± ì‹œ ë°˜ë“œì‹œ í—¤ë” êµ¬ë¶„ì„ ìœ„í•œ êµ¬ë¶„ì„ (`| :--- | :--- |`)ì„ ìƒëµí•˜ì§€ ë§ˆì„¸ìš”.

# [FORMATTING RULE] CONCISE TONE & LINE BREAKS
- ëª¨ë“  ë¬¸ì¥ì€ **ëª…ì‚¬í˜• ì–´ë¯¸**(~í•¨, ~ì„, ~í•„ìš”, ~ì¤€ë¹„ ë“±)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
- ì¤„ë°”ê¿ˆì´ í•„ìš”í•œ ê²½ìš° ë°˜ë“œì‹œ ì‹¤ì œ ì¤„ë°”ê¿ˆ(`\\n`)ì„ ì‚¬ìš©í•˜ì„¸ìš”. **`<br>` íƒœê·¸ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**

# [CITATION RULE]
- **í˜ì´ì§€ ì¸ì‹**: í…ìŠ¤íŠ¸ ë‚´ì˜ `[Page N]` í‘œì‹œê°€ í•´ë‹¹ í˜ì´ì§€ì˜ ì‹œì‘ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
- **ì„¹ì…˜ 1, 2, 3, 4, 5, 6 (í‘œ)**: í‘œ ë‚´ë¶€ì˜ ì…€ì— **ì¶œì²˜ë¥¼ ì¤‘ë³µí•´ì„œ í‘œê¸°í•˜ì§€ ë§ˆì„¸ìš”.** í‘œì—ëŠ” ì „ìš© 'ì¶œì²˜' ì—´ì´ ìˆëŠ” ê²½ìš° ê·¸ê³³ì—ë§Œ í‘œê¸°í•˜ì„¸ìš”. (ì˜ˆ: ì„¹ì…˜ 3ì˜ 'ìƒì„¸ ìˆ˜í–‰ ë‚´ìš©' ì¹¸ì—ëŠ” ì¶œì²˜ë¥¼ ì ì§€ ë§ˆì„¸ìš”.)
- **ì¼ë°˜ í…ìŠ¤íŠ¸**: ê° ê·¼ê±° ë’¤ì— ë°˜ë“œì‹œ ê´„í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë§Œ í‘œê¸°í•˜ì„¸ìš” (ì˜ˆ: (10p)).

# [OUTPUT TAGS]
- ë‹µë³€ ìµœìƒë‹¨ì— ë°˜ë“œì‹œ í•´ë‹¹ ì‚¬ì—…ì˜ ê³µì‹ ëª…ì¹­ì„ **[PROJECT_NAME: ê³µì‹ê³¼ì—…ëª…]** í˜•ì‹ìœ¼ë¡œ í•œ ì¤„ ì ìœ¼ì„¸ìš”. (ì˜ˆ: [PROJECT_NAME: 2024ë…„ ê³ ë¦½Â·ì€ë‘” ì²­ë…„ ì‹¤íƒœì¡°ì‚¬])

# Analysis Instructions
ì•„ë˜ ì„¹ì…˜ì— ë§ì¶° ë¶„ì„ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
{section_1_prompt}

## 2. ë°°ì í‘œ ê¸°ë°˜ ìŠ¹ë¶€ì²˜ ë¶„ì„ (Scoring Strategy)
**ë°°ì ì´ ë†’ê±°ë‚˜ ì¤‘ìš”í•œ ìš”ê±´ 3ê°€ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.**

| ì£¼ìš” ìš”ê±´ | ë°°ì  | ìƒì„¸ ë‚´ìš© ë° ì „ëµ | ì¶œì²˜ |
| :--- | :--- | :--- | :--- |
| | | | |
| | | | |
| | | | |

## 3. ê³¼ì—… ë‚´ìš© ê¸°ë°˜ í•„ìˆ˜ ìˆ˜í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Must-Do List)
**ê³¼ì—…ì§€ì‹œì„œìƒ í•„ìˆ˜ ìˆ˜í–‰ ê³¼ì—…ì„ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”. [ì¤‘ìš”] ë°˜ë“œì‹œ ì œì•ˆìš”ì²­ì„œì˜ 'ëª©ì°¨' ìˆœì„œì— ë§ì¶”ì–´ ì¬ë°°ì¹˜í•˜ê³ , ìƒì„¸ ìˆ˜í–‰ ë‚´ìš©ì€ ì„¸ë¯¸ì½œë¡ (; )ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‹œì¸ì„±ì„ ë†’ì´ì„¸ìš”.**

| ìˆœì„œ | í•„ìˆ˜ ê³¼ì—… ë‚´ìš© | ìƒì„¸ ìˆ˜í–‰ ë‚´ìš© | ì¶œì²˜ |
| :--- | :--- | :--- | :--- |
| | | | |

## 4. í–‰ì • ì„œë¥˜ ë° ì œì•ˆì„œ ê·œê²© ì²´í¬ë¦¬ìŠ¤íŠ¸ (Administrative Check)
**ì œì¶œ ì„œë¥˜ ë° ê·œê²©ì„ ì •ë¦¬í•˜ê³  ì¶œì²˜ í˜ì´ì§€ë¥¼ í‘œê¸°í•˜ì„¸ìš”.**

## 5. ìƒì„¸ ì „ëµ ë° ê°€ì  ìš”ì¸ (Bonus Strategy)
**ê°€ì  í•­ëª© ë° ì „ëµì  ì œì–¸ì„ ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.**

| êµ¬ë¶„ | ìƒì„¸ ë‚´ìš© | ì „ëµì  ì œì–¸ |
| :--- | :--- | :--- |
| **ê°€ì  í•­ëª©** | | |
| **ì°¨ë³„í™” ìš”ì†Œ** | | |
| **í•µì‹¬ ì œì–¸** | | |

## 6. ì œì•ˆì„œ ëª©ì°¨ ë° êµ¬ì„±ì•ˆ (Proposal Skeleton)
**ë¶„ì„ëœ ê³¼ì—…ê³¼ ë°°ì ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¹ë¥ ì„ ë†’ì´ëŠ” ìµœì ì˜ ì œì•ˆì„œ êµ¬ì„±(Skeleton)ì„ ì œì•ˆí•˜ì„¸ìš”.**

| ëŒ€ëª©ì°¨ | ì¤‘/ì†Œëª©ì°¨ | í•µì‹¬ í¬í•¨ ë‚´ìš© ë° ì „ëµ | ë¹„ì¤‘(%) |
| :--- | :--- | :--- | :--- |
| | | | |
"""
            # Use a balanced slice of the text (Optimized for tokens)
            def get_balanced_context(text, max_chars=20000):
                if not text: return ""
                if len(text) <= max_chars: return text
                half = max_chars // 2
                return text[:half] + "\n\n... (ì¤‘ëµ) ...\n\n" + text[-half:]

            user_content = f"[ê¸ˆë…„ë„ ë¬¸ì„œ]\n{get_balanced_context(full_current_text, 20000)}\n\n[ì§ì „ íšŒì°¨ ë¬¸ì„œ]\n{get_balanced_context(prev_text, 8000) if prev_text else 'ì—†ìŒ'}"
            
            # Detect project name and store in session state
            project_name = detect_project_name(user_content)
            st.session_state.analysis_results["project_name"] = project_name
            
            # 1. Main RFP Analysis
            prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
            
            with st.spinner(f"[{project_name}] ì „ë¬¸ê°€ ëª¨ë“œ ì •ë°€ ë¶„ì„ ì¤‘..."):
                response = invoke_with_retry(prompt, {"text": user_content}, api_keys, groq_api_key=groq_api_key, model_name=MODEL_NAME)
                
                # Extract AI-detected project name (fallback)
                ai_name_match = re.search(r'\[PROJECT_NAME:\s*(.*?)\]', response)
                if ai_name_match:
                    project_name = ai_name_match.group(1).strip()
                    st.session_state.analysis_results["project_name"] = project_name
                    response = response.replace(ai_name_match.group(0), "").strip()
                
                cleaned_response = clean_ai_output(response)
                st.session_state.analysis_results["main_analysis"] = cleaned_response

            # 2. Similar Research Discovery (Search & Sort)
            with st.spinner("ìœ ì‚¬ í•™ìˆ ì—°êµ¬ ë° ë³´ë„ìë£Œ ê²€ìƒ‰ ì¤‘..."):
                try:
                    search_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ í•™ìˆ ì—°êµ¬ ì „ë¬¸ ì‚¬ì„œì´ì ì •ë¶€ ë³´ê³ ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ [ê³¼ì—…ëª…]ê³¼ ìœ ì‚¬í•œ **êµ­ë‚´** í•™ìˆ  ì—°êµ¬, ë…¼ë¬¸, ê·¸ë¦¬ê³  ì •ë¶€/ê³µê³µê¸°ê´€ì˜ ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ 7~10ê°œ ì •ë„ ì°¾ì•„ë‚´ì–´ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.
**[ì¤‘ìš”] ë°˜ë“œì‹œ êµ­ë‚´ ìë£Œë§Œ ë¦¬ìŠ¤íŠ¸ì—…í•˜ê³ , í•´ì™¸ ì—°êµ¬ëŠ” ì œì™¸í•˜ì„¸ìš”.**
**[ì¤‘ìš”] ë°˜ë“œì‹œ ìµœê·¼ 2ë…„ ì´ë‚´(2024ë…„ 1ì›” ~ 2026ë…„ í˜„ì¬)ì— ë°œí‘œ/ë°œê°„ëœ ìë£Œì—¬ì•¼ í•©ë‹ˆë‹¤.**

[ê³¼ì—…ëª…]
{project_name}

[ë¶„ì„ ì§€ì¹¨]
1. **í•™ìˆ  ì—°êµ¬(ë…¼ë¬¸)**ë¥¼ ìµœìš°ì„ ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì—…í•˜ì„¸ìš”.
2. ê° í•­ëª©ì— ëŒ€í•´ ì•„ë˜ ì •ë³´ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”:
   - ì—°ë„: ì—°ë„ 4ìë¦¬
   - ë…¼ë¬¸/ë³´ê³ ì„œëª…: ì—°êµ¬ì˜ ì •ì‹ ì œëª©
   - ì €ìëª…: ëŒ€í‘œ ì €ìëª…
   - ì €ì ì†Œì†ê¸°ê´€: ëŒ€í•™êµ ë˜ëŠ” ì—°êµ¬ê¸°ê´€ëª…
   - ë³´ê³ ì„œ ë°œê°„ ê¸°ê°„: (ì˜ˆ: 2023.01 ~ 2023.12 ë˜ëŠ” ë‹¨ì¼ ì‹œì )
3. **ì •ë ¬ ê·œì¹™**:
   - 1ìˆœìœ„: í•™ìˆ ì—°êµ¬(ë…¼ë¬¸) ì—¬ë¶€ (ë…¼ë¬¸ì„ ìƒë‹¨ì—)
   - 2ìˆœìœ„: ì €ìëª… ê°€ë‚˜ë‹¤/ABC ìˆœ
   - 3ìˆœìœ„: ì†Œì†ê¸°ê´€ ê°€ë‚˜ë‹¤/ABC ìˆœ
4. í‘œ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš” (| ì—°ë„ | ë…¼ë¬¸/ë³´ê³ ì„œëª… | ì €ìëª… | ì €ì ì†Œì†ê¸°ê´€ | ë³´ê³ ì„œ ë°œê°„ ê¸°ê°„ |).
5. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì—°êµ¬ ë°ì´í„°ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
""")
                    research_result = invoke_with_retry(search_prompt, {"project_name": project_name}, api_keys, groq_api_key=groq_api_key, use_flash=False, model_name=MODEL_NAME)
                    st.session_state.analysis_results["similar_research"] = clean_ai_output(research_result)
                except Exception as e:
                    st.session_state.analysis_results["similar_research"] = f"ìœ ì‚¬ì—°êµ¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

            # 3. Pre-generate Docx report
            import report_utils
            report_data = {
                "ì œì•ˆìš”ì²­ì„œ ë¶„ì„ ê²°ê³¼": st.session_state.analysis_results["main_analysis"],
                "ìœ ì‚¬ì—°êµ¬ ë¶„ì„ ë¦¬ìŠ¤íŠ¸": st.session_state.analysis_results.get("similar_research", "")
            }
            st.session_state.analysis_results["docx_file"] = report_utils.generate_word_report(report_data, project_name=project_name)

        except Exception as e:
            st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {type(e).__name__}: {e}")
            with st.expander("ğŸ› ï¸ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ (ë””ë²„ê¹…ìš©)"):
                st.code(traceback.format_exc())
            
            # Diagnostic for 404
            if "NOT_FOUND" in str(e) or "not found" in str(e).lower():
                with st.expander("ğŸ› ï¸ API ëª¨ë¸ ì ‘ê·¼ ì§„ë‹¨"):
                    try:
                        genai.configure(api_key=api_key)
                        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                        st.write("í˜„ì¬ API í‚¤ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
                        st.code("\n".join(models))
                    except: pass

    # --- Persistent Display Area ---
    if "analysis_results" in st.session_state and st.session_state.analysis_results:
        tabs = st.tabs(["ğŸ“‹ ì œì•ˆìš”ì²­ì„œ ë¶„ì„ ê²°ê³¼", "ğŸ” ìœ ì‚¬ì—°êµ¬"])

        with tabs[0]:
            project_name = st.session_state.analysis_results.get("project_name", "ë¯¸ì§€ì • ì‚¬ì—…")
            st.header(f"ğŸ“‹ ì œì•ˆìš”ì²­ì„œ ë¶„ì„ ê²°ê³¼ [{project_name}]")
            analysis_text = st.session_state.analysis_results.get("main_analysis", "")
            st.markdown(analysis_text, unsafe_allow_html=True)

            st.markdown("---")
            st.warning("âš ï¸ **[ì£¼ì˜] í˜„ì¬ ë¶„ì„ ê²°ê³¼ëŠ” ì„ì‹œ ìƒíƒœì…ë‹ˆë‹¤. í•˜ë‹¨ 'ì›Œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ë¬¼ì„ ì €ì¥í•˜ì„¸ìš”. ìƒˆë¡œìš´ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ë©´ ê¸°ì¡´ ë‚´ìš©ì€ ì‚¬ë¼ì§‘ë‹ˆë‹¤.**")

        with tabs[1]:
            st.header("ğŸ” ìœ ì‚¬ì—°êµ¬")
            st.info("ğŸ’¡ ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ì œì•ˆì„œ ì‘ì„±ì„ ìœ„í•œ ìë¬¸ìœ„ì› ì„­ì™¸ë¥¼ ë•ê¸° ìœ„í•´ ê´€ë ¨ ì—°êµ¬ìì™€ ìœ ê´€ê¸°ê´€ ì „ë¬¸ê°€ë¥¼ í†µí•© ê²€ìƒ‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
            research_text = st.session_state.analysis_results.get("similar_research", "")
            if research_text:
                st.markdown(research_text, unsafe_allow_html=True)
            else:
                st.info("ìœ ì‚¬ì—°êµ¬ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # Display cached download button
        if st.session_state.analysis_results.get("docx_file"):
            st.markdown("---")
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì›Œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=st.session_state.analysis_results["docx_file"],
                file_name="win_strategy_report.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="primary",
                use_container_width=True,
                key="final_dw_btn_stable_cached"
            )
st.markdown('<div class="footer">Developed by ã…ˆã……ã…<br>jeon080423@gmail.com | Powered by Streamlit & Google Gemini</div>', unsafe_allow_html=True)
