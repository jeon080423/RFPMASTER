
import streamlit as st
import pdfplumber
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re
import os
from kiwipiepy import Kiwi
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import datetime
import time
import auth
import email_utils

# -----------------------------------------------------------------------------
# 1. Config & Branding
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ìˆ˜ì£¼ë¹„ì±… - RFP ë¶„ì„ ì†”ë£¨ì…˜",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem; font-weight: 800; text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.1rem; text-align: center; color: #888;
        margin-bottom: 1.5rem;
    }
    .footer {
        text-align: center; color: #aaa; font-size: 0.85rem;
        margin-top: 3rem; padding: 1rem 0;
        border-top: 1px solid #eee;
    }
    /* Sidebar login styling */
    .sidebar-login-header {
        font-size: 1.1rem; font-weight: 700; margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. Authentication (Sidebar)
# -----------------------------------------------------------------------------
auth.init_db()

if "user" not in st.session_state:
    st.session_state.user = None

# --- Sidebar ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2921/2921222.png", width=50)
    
    if st.session_state.user:
        # --- Logged-in state ---
        st.success(f"ğŸ‘¤ **{st.session_state.user['name']}**ë‹˜ ì ‘ì† ì¤‘")
        
        if not st.session_state.user.get('approved', False):
            st.warning("â³ ê³„ì • ìŠ¹ì¸ ëŒ€ê¸° ì¤‘")
        
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_sidebar", use_container_width=True):
            st.session_state.user = None
            st.rerun()
        
        # Admin Logic
        if st.session_state.user.get('role') == 'admin':
            st.markdown("---")
            st.subheader("ğŸ‘‘ ê´€ë¦¬ì ë©”ë‰´")
            pending_users = auth.get_pending_users()
            if not pending_users.empty:
                st.warning(f"ìŠ¹ì¸ ëŒ€ê¸°: {len(pending_users)}ëª…")
                for _, row in pending_users.iterrows():
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"**{row['name']}** ({row['email']})")
                    with col2:
                        if st.button("ìŠ¹ì¸", key=f"btn_{row['email']}"):
                            auth.approve_user(row['email'])
                            success, form = email_utils.send_approval_email(row['email'])
                            if success:
                                st.success(f"ìŠ¹ì¸ ì™„ë£Œ!")
                            else:
                                st.warning(f"ìŠ¹ì¸ ì™„ë£Œ, ë©”ì¼ ì‹¤íŒ¨")
                            st.rerun()
            else:
                st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ íšŒì› ì—†ìŒ")
    else:
        # --- Not logged-in state ---
        st.markdown('<div class="sidebar-login-header">ğŸ” ë¡œê·¸ì¸</div>', unsafe_allow_html=True)
        
        login_tab, signup_tab = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"])
        
        with login_tab:
            email = st.text_input("ì´ë©”ì¼", key="login_email")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")
            if st.button("ë¡œê·¸ì¸", type="primary", use_container_width=True):
                user = auth.login_user(email, password)
                if user:
                    st.session_state.user = user
                    st.rerun()
                else:
                    st.error("ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with signup_tab:
            new_email = st.text_input("ì´ë©”ì¼", key="signup_email")
            new_name = st.text_input("ì´ë¦„", key="signup_name")
            new_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="signup_pw")
            new_password_confirm = st.text_input("ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="signup_pw_chk")
            
            if st.button("ê°€ì…í•˜ê¸°", use_container_width=True):
                if new_password != new_password_confirm:
                    st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                elif not new_email or not new_password or not new_name:
                    st.error("ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    if auth.create_user(new_email, new_password, new_name):
                        email_utils.send_admin_notification(new_email, new_name)
                        st.success("ê°€ì… ìš”ì²­ ì™„ë£Œ! ê´€ë¦¬ì ìŠ¹ì¸ í›„ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    else:
                        st.error("ì´ë¯¸ ê°€ì…ëœ ì´ë©”ì¼ì…ë‹ˆë‹¤.")
    
    # Settings
    st.markdown("---")
    api_key = st.secrets.get("groq", {}).get("api_key", "")
    if not api_key:
        api_key = os.environ.get("GROQ_API_KEY", "")
    
    st.markdown("---")
    st.markdown("**Developed by ã…ˆã……ã…**")

# -----------------------------------------------------------------------------
# 3. Utility Functions
# -----------------------------------------------------------------------------
def mask_pii(text):
    rrn_pattern = r'\d{6}[-\s]\d{7}'
    masked_text = re.sub(rrn_pattern, '******-*******', text)
    return masked_text

def extract_text_from_pdf(uploaded_file):
    text = ""
    try:
        with pdfplumber.open(uploaded_file) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        return f"Error reading PDF: {e}"
    return mask_pii(text)

def analyze_keywords(text):
    kiwi = Kiwi()
    tokens = kiwi.tokenize(text[:200000])
    nouns = [token.form for token in tokens if token.tag.startswith('NN') and len(token.form) > 1]
    stopwords = ['ëŒ€í•œ', 'ê´€ë ¨', 'ìœ„í•´', 'ê²½ìš°', 'ì‚¬í•­', 'ì´ìƒ', 'ì´í•˜', 'ê¸°íƒ€', 'í¬í•¨', 'ìˆ˜í–‰', 'ì‘ì„±', 'ì œì¶œ', 'í•´ë‹¹']
    nouns = [n for n in nouns if n not in stopwords]
    count = Counter(nouns)
    return count.most_common(20)

def create_word_chart(keywords):
    if not keywords: return None
    words, counts = zip(*keywords)
    fig, ax = plt.subplots(figsize=(10, 6))
    import platform
    import matplotlib.font_manager as fm
    
    system_name = platform.system()
    if system_name == 'Windows':
        plt.rc('font', family='Malgun Gothic')
    elif system_name == 'Darwin':
        plt.rc('font', family='AppleGothic')
    else:
        paths = [
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf'
        ]
        font_name = None
        for path in paths:
            if os.path.exists(path):
                font_name = fm.FontProperties(fname=path).get_name()
                break
        if font_name:
            plt.rc('font', family=font_name)
        else:
            plt.rc('font', family='NanumGothic')
    
    plt.rc('axes', unicode_minus=False)
    ax.barh(words, counts, color='#3B82F6')
    ax.invert_yaxis()
    ax.set_xlabel('ë¹ˆë„ìˆ˜')
    ax.set_title('ìƒìœ„ 20ê°œ í•µì‹¬ í‚¤ì›Œë“œ')
    return fig

def get_relevant_context(text, keywords, box_size=2000, max_len=4000):
    """Extracts relevant text chunks around keywords. Sizes reduced for Groq TPM limit."""
    relevant_chunks = []
    text_lower = text.lower()
    for kw in keywords:
        start_idx = 0
        while True:
            idx = text_lower.find(kw, start_idx)
            if idx == -1: break
            start = max(0, idx - 500)
            end = min(len(text), idx + box_size)
            chunk = text[start:end]
            relevant_chunks.append(chunk)
            start_idx = idx + len(kw)
    if not relevant_chunks:
        return text[:max_len]
    combined = "\n...\n".join(relevant_chunks)
    return combined[:max_len]

# -----------------------------------------------------------------------------
# 4. Main Content (Always visible)
# -----------------------------------------------------------------------------
st.markdown('<div class="main-header">ìˆ˜ì£¼ë¹„ì±… (Win Strategy)</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ê³µê³µê¸°ê´€ ì…ì°° ì„±ê³µì„ ìœ„í•œ ì œì•ˆìš”ì²­ì„œ(RFP) ì‹¬ì¸µ ë¶„ì„ ì†”ë£¨ì…˜</div>', unsafe_allow_html=True)

# Rate limit retry helper
def invoke_with_retry(chain, params, max_retries=3):
    """Invoke LLM chain with retry on rate limit errors."""
    for attempt in range(max_retries):
        try:
            return chain.invoke(params)
        except Exception as e:
            error_str = str(e)
            if 'rate_limit' in error_str.lower() or '413' in error_str or '429' in error_str:
                wait_time = 15 * (attempt + 1)
                time.sleep(wait_time)
            else:
                raise e
    raise Exception("API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

st.info("âš ï¸ ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ëª¨ë“  ë¬¸ì„œëŠ” **PDF í˜•ì‹**ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    st.subheader("1. ê¸ˆë…„ë„ ê³µê³  ìë£Œ (í•„ìˆ˜)")
    st.markdown("<div style='margin-bottom: 28px;'></div>", unsafe_allow_html=True)
    current_rfp = st.file_uploader("ì˜¬í•´ ì œì•ˆìš”ì²­ì„œ ì—…ë¡œë“œ", type=["pdf"], key="curr_rfp")
    no_task_desc = st.checkbox("ê³¼ì—…ì§€ì‹œì„œ ì—†ìŒ (ì œì•ˆìš”ì²­ì„œ ë‚´ í¬í•¨)", key="chk_no_task")
    current_task = st.file_uploader("ì˜¬í•´ ê³¼ì—…ì§€ì‹œì„œ ì—…ë¡œë“œ", type=["pdf"], disabled=no_task_desc, key="curr_task")

with col2:
    st.subheader("2. ì§ì „ ì—°ë„ ê³µê³  ìë£Œ (ì„ íƒ)")
    no_prev_rfp = st.checkbox("ì§ì „ ì œì•ˆìš”ì²­ì„œ ì—†ìŒ", key="chk_no_prev_rfp")
    prev_rfp = st.file_uploader("ì§ì „ ì—°ë„ ì œì•ˆìš”ì²­ì„œ ì—…ë¡œë“œ", type=["pdf"], disabled=no_prev_rfp, key="prev_rfp")
    no_prev_task = st.checkbox("ì§ì „ ê³¼ì—…ì§€ì‹œì„œ ì—†ìŒ", key="chk_no_prev_task")
    prev_task = st.file_uploader("ì§ì „ ì—°ë„ ê³¼ì—…ì§€ì‹œì„œ ì—…ë¡œë“œ", type=["pdf"], disabled=no_prev_task, key="prev_task")

# --- Conditional: Show analysis button only for logged-in & approved users ---
is_logged_in = st.session_state.user is not None
is_approved = is_logged_in and st.session_state.user.get('approved', False)

if not is_logged_in:
    st.warning("ğŸ”’ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•˜ë ¤ë©´ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ **ë¡œê·¸ì¸**í•´ ì£¼ì„¸ìš”.")
    start_analysis = False
elif not is_approved:
    st.warning("â³ ê³„ì • ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    start_analysis = False
else:
    start_analysis = st.button("ì œì•ˆìš”ì²­ì„œ ë¶„ì„ ì‹œì‘ ğŸš€", type="primary", use_container_width=True)

# -----------------------------------------------------------------------------
# 5. Analysis Logic (only for approved users)
# -----------------------------------------------------------------------------
if start_analysis:
    if not api_key:
        st.error("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ API Key ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    if not current_rfp:
        st.error("ì˜¬í•´ ì œì•ˆìš”ì²­ì„œëŠ” í•„ìˆ˜ ì—…ë¡œë“œ í•­ëª©ì…ë‹ˆë‹¤.")
        st.stop()

    with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        curr_rfp_text = extract_text_from_pdf(current_rfp)
        curr_task_text = ""
        if not no_task_desc and current_task:
            curr_task_text = extract_text_from_pdf(current_task)
        full_current_text = curr_rfp_text + "\n" + curr_task_text
        
        prev_text = ""
        if not no_prev_rfp and prev_rfp:
            prev_text += extract_text_from_pdf(prev_rfp) + "\n"
        if not no_prev_task and prev_task:
            prev_text += extract_text_from_pdf(prev_task)
        
        top_keywords = analyze_keywords(full_current_text)

    st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    try:
        MODEL_NAME = "llama-3.3-70b-versatile"
        llm = ChatGroq(temperature=0.0, model=MODEL_NAME, api_key=api_key)

        has_prev = bool(prev_text.strip())

        tabs = st.tabs(["ğŸ“Š í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸", "ğŸ”¬ ì¡°ì‚¬/ë¶„ì„ ì„¤ê³„", "ğŸ“ í‘œë³¸/í’ˆì§ˆ ê´€ë¦¬", "ï¿½ ì‚¬ì—… ê´€ë¦¬", "ğŸ“„ ì¤€ë¹„ì„œë¥˜", "âœ… ëª©ì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸", "ğŸ¯ ìƒì„¸ ì „ëµ"])
        
        if "analysis_results" not in st.session_state:
            st.session_state.analysis_results = {}

        # =====================================================================
        # Common: run_analysis (no comparison)
        # =====================================================================
        def run_analysis(tab_name, instructions, keywords, context_text, target_tab):
            with target_tab:
                st.header(tab_name)
                relevant_text = get_relevant_context(context_text, keywords)
                with st.spinner(f"{tab_name} ë¶„ì„ ì¤‘..."):
                    try:
                        time.sleep(3)
                        # st.toast("API í˜¸ì¶œ ì¤€ë¹„ ì¤‘... (ì ì‹œ ëŒ€ê¸°)", icon="â³")
                        sys_prompt = (
                            "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ë° ì œì•ˆìš”ì²­ì„œ(RFP) ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                            "ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:\n"
                            "1. ë¬¸ì„œì— ìˆëŠ” 'ì‚¬ì‹¤(Fact)'ë§Œì„ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬í•˜ì„¸ìš”.\n"
                            "2. ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë„êµ¬, ê¸°ìˆ , ë°©ë²•ë¡ , ì˜ê²¬ì€ ì ˆëŒ€ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                            "3. ë‚´ìš©ì´ ì—†ìœ¼ë©´ 'í•´ë‹¹ ë‚´ìš© ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\n"
                            "4. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ(table) í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. í‘œ ì™¸ì— ë¶ˆë¦¿ ëª©ë¡ì´ë‚˜ í…ìŠ¤íŠ¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                            "5. HTML íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³  ë§ˆí¬ë‹¤ìš´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                            "6. ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ 'í•œêµ­ì–´'ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n"
                            "7. ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´, ì•„ëì–´ê°€ ì ˆëŒ€ í¬í•¨ë˜ì§€ ì•Šê²Œ í•˜ì„¸ìš”.\n"
                            "8. ë°œì£¼ê¸°ê´€ë§ˆë‹¤ ìš©ì–´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ìš©ì–´ëŠ” ê°™ì€ í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. "
                            "ì˜ˆ: 'ê³¼ì—…ë²”ìœ„'='ì‚¬ì—…ë²”ìœ„'='ìˆ˜í–‰ë²”ìœ„', 'ëª¨ì§‘ë‹¨'='ì¡°ì‚¬ëŒ€ìƒ', 'ì‚¬ì—…ë¹„'='ì˜ˆì‚°'='ìš©ì—­ë¹„' ë“±\n\n"
                            f"[ë¶„ì„ ì§€ì‹œì‚¬í•­]\n{instructions}"
                        )
                        prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
                        chain = prompt | llm | StrOutputParser()
                        response = invoke_with_retry(chain, {"text": relevant_text})
                        response = response.replace("<br>", " ").replace("<br/>", " ")
                        st.markdown(response)
                        st.session_state.analysis_results[tab_name] = response
                    except Exception as e:
                        st.error(f"{tab_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # =====================================================================
        # Common: run_comparison_analysis
        # Refactored: Always show Current Analysis (List Format) + Comparison (Table if exists)
        # =====================================================================
        def run_comparison_analysis(tab_name, instructions_current, instructions_compare, keywords, current_text, previous_text, target_tab):
            """Analyze current doc (New List Format), then compare with previous if available."""
            with target_tab:
                st.header(tab_name)
                relevant_current = get_relevant_context(current_text, keywords)
                
                # 1. Current Analysis (Senior Researcher Persona, List Format)
                with st.spinner(f"{tab_name} - ê¸ˆë…„ë„ í•µì‹¬ ìš”ê±´ ë¶„ì„ ì¤‘..."):
                    try:
                        time.sleep(3)
                        # st.toast("API í˜¸ì¶œ ì¤€ë¹„ ì¤‘... (ì ì‹œ ëŒ€ê¸°)", icon="â³")
                        # New Persona and Goal from User Request
                        sys_prompt = (
                            "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ë° ì •ë¶€ ë¶€ì²˜ì˜ ì¡°ì‚¬Â·ì—°êµ¬ ìš©ì—­ ì œì•ˆì„œë¥¼ ì‘ì„±í•˜ëŠ” ìˆ˜ì„ ì—°êµ¬ì›(Senior Researcher)ì…ë‹ˆë‹¤.\n"
                            "ì—…ë¡œë“œëœ ì œì•ˆìš”ì²­ì„œì˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬, ì œì•ˆì„œ ë³¸ë¬¸ì— ê¸°ìˆ í•´ì•¼ í•  í•µì‹¬ ê³¼ì—… ìš”ê±´ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n\n"
                            "# Analysis Goal\n"
                            "ì œì•ˆì„œì˜ 'ìˆ˜í–‰ ê³„íš' íŒŒíŠ¸ë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•´, ë°œì£¼ì²˜ê°€ ìš”êµ¬í•˜ëŠ” êµ¬ì²´ì ì¸ ì¡°ì‚¬ ë°©ë²•, ì ˆì°¨, ë¶„ì„ ìˆ˜ì¤€, ê´€ë¦¬ ìš”ê±´ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
                            "# Output Rule\n"
                            "1. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸(Bulleted List) í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”. (í‘œ ì‚¬ìš© ì§€ì–‘)\n"
                            "2. ê° í•­ëª©ì˜ í•µì‹¬ ë‚´ìš©ì€ **êµµê²Œ(Bold)** í‘œì‹œí•˜ì„¸ìš”.\n"
                            "3. ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ì´ ìˆìœ¼ë©´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì¡°ê±´ì„ ì ê³ , í•´ë‹¹ ë‚´ìš©ì´ ë°œê²¬ëœ í˜ì´ì§€ë‚˜ ë¬¸ë§¥ì´ ìˆë‹¤ë©´ [ì¶œì²˜]ë¥¼ ê°„ëµíˆ í‘œê¸°í•˜ì„¸ìš”.\n"
                            "4. ë‚´ìš©ì´ ì—†ìœ¼ë©´ 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'ìœ¼ë¡œ ì ìœ¼ì„¸ìš”.\n"
                            "5. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n\n"
                            f"# Analysis Scope (Categories to Extract)\n{instructions_current}"
                        )
                        prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
                        chain = prompt | llm | StrOutputParser()
                        response = invoke_with_retry(chain, {"text": relevant_current})
                        response = response.replace("<br>", " ").replace("<br/>", " ")
                        
                        st.subheader("ï¿½ ê¸ˆë…„ë„ í•µì‹¬ ê³¼ì—… ìš”ê±´")
                        st.markdown(response)
                        st.session_state.analysis_results[tab_name] = response
                    except Exception as e:
                        st.error(f"{tab_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

                # 2. Previous Comparison (Table Format, Only if prev exists)
                if previous_text.strip():
                    relevant_prev = get_relevant_context(previous_text, keywords)
                    with st.spinner(f"{tab_name} - ì§ì „ ì—°ë„ ëŒ€ë¹„ ë¹„êµ ë¶„ì„ ì¤‘..."):
                        try:
                            time.sleep(5)
                            compare_prompt = ChatPromptTemplate.from_template(
                                "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                                "ì•„ë˜ [ì§ì „ ì—°ë„]ì™€ [ê¸ˆë…„ë„] ë¬¸ì„œë¥¼ ë¹„êµí•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ ë¶„ì„í•˜ì„¸ìš”.\n\n"
                                "**í•µì‹¬ ê·œì¹™:**\n"
                                "- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ(Table) í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                                "- ë°œì£¼ê¸°ê´€ë§ˆë‹¤ ìš©ì–´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ìœ ì—°í•˜ê²Œ ë¹„êµí•˜ì„¸ìš”.\n"
                                "- 'ë¹„ê³ ' ì—´ì—ëŠ” ë³€ê²½ì´ ìˆ˜ì£¼ ì „ëµì— ë¯¸ì¹˜ëŠ” ì‹œì‚¬ì ì„ ìš”ì•½í•˜ì„¸ìš”.\n\n"
                                f"{instructions_compare}\n\n"
                                "[ì§ì „ ì—°ë„ ë¬¸ì„œ]\n{prev_text}\n\n[ê¸ˆë…„ë„ ë¬¸ì„œ]\n{curr_text}"
                            )
                            chain = compare_prompt | llm | StrOutputParser()
                            compare_res = invoke_with_retry(chain, {"prev_text": relevant_prev, "curr_text": relevant_current})
                            compare_res = compare_res.replace("<br>", " ").replace("<br/>", " ")
                            
                            st.subheader("ï¿½ ì§ì „ ì—°ë„ ëŒ€ë¹„ ë³€ê²½ ì‚¬í•­")
                            st.markdown(compare_res)
                            st.session_state.analysis_results[f"{tab_name} (ë¹„êµ)"] = compare_res
                        except Exception as e:
                            st.error(f"{tab_name} ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

        # =====================================================================
        # Common: run_task_comparison_analysis (Specific for Tab 4)
        # =====================================================================
        def run_task_comparison_analysis(tab_name, instructions_current, keywords, current_text, previous_text, target_tab):
            """Specific comparison for Task Description (Scope, Content, Cautions)."""
            with target_tab:
                st.header(tab_name)
                relevant_current = get_relevant_context(current_text, keywords)
                
                # 1. Current Task Analysis
                with st.spinner(f"{tab_name} - ê¸ˆë…„ë„ ê³¼ì—… ë¶„ì„ ì¤‘..."):
                    try:
                        time.sleep(3)
                        # st.toast("API í˜¸ì¶œ ì¤€ë¹„ ì¤‘... (ì ì‹œ ëŒ€ê¸°)", icon="â³")
                        sys_prompt = (
                            "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ê³¼ì—…ì§€ì‹œì„œ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                            "ì œì•ˆì„œ ì‘ì„±ì— í•„ìˆ˜ì ì¸ ê³¼ì—… ìˆ˜í–‰ ìš”ê±´ì„ ì•„ë˜ ê¸°ì¤€ì— ë§ì¶° ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
                            "# Output Rule\n"
                            "- ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
                            "- ë¬¸ì„œì— ëª…ì‹œëœ 'í•„ìˆ˜' ì‚¬í•­ì„ ë¹ ì§ì—†ì´ ê¸°ë¡í•˜ì„¸ìš”.\n\n"
                            f"{instructions_current}"
                        )
                        prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
                        chain = prompt | llm | StrOutputParser()
                        response = invoke_with_retry(chain, {"text": relevant_current})
                        st.subheader("ï¿½ ê¸ˆë…„ë„ í•„ìˆ˜ ê³¼ì—… ìš”ê±´")
                        st.markdown(response)
                        st.session_state.analysis_results[tab_name] = response
                    except Exception as e:
                        st.error(f"{tab_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

                # 2. Comparison Analysis
                if previous_text.strip():
                    relevant_prev = get_relevant_context(previous_text, keywords)
                    with st.spinner(f"{tab_name} - ê³¼ì—…ì§€ì‹œì„œ ë¹„êµ ë¶„ì„ ì¤‘..."):
                        try:
                            time.sleep(5)
                            compare_prompt = ChatPromptTemplate.from_template(
                                "ë‹¹ì‹ ì€ ê³¼ì—…ì§€ì‹œì„œ ë¹„êµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
                                "ì•„ë˜ [ì§ì „ ê³¼ì—…ì§€ì‹œì„œ]ì™€ [ê¸ˆë…„ë„ ê³¼ì—…ì§€ì‹œì„œ]ë¥¼ ë¹„êµí•˜ì—¬,\n"
                                "**ì¡°ì‚¬ ë²”ìœ„, ê³¼ì—… ë‚´ìš©, ì£¼ì˜ì‚¬í•­(íŠ¹ì´ì‚¬í•­)** ì¸¡ë©´ì—ì„œ ìƒì„¸íˆ ë¹„êµí•˜ì„¸ìš”.\n\n"
                                "**í•µì‹¬ ê·œì¹™:**\n"
                                "- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                                "- 'ë¹„ê³ ' ì—´ì—ëŠ” ë³€ê²½ì‚¬í•­ ëŒ€ì‘ ì „ëµì„ ê¸°ìˆ í•˜ì„¸ìš”.\n\n"
                                "**[ë¹„êµ í•­ëª©]**\n"
                                "| êµ¬ë¶„ | ì§ì „ ê³¼ì—…ì§€ì‹œì„œ | ê¸ˆë…„ë„ ê³¼ì—…ì§€ì‹œì„œ | ë¹„ê³ (ì œì•ˆ ì „ëµ) |\n"
                                "|---|---|---|---|\n"
                                "| ì¡°ì‚¬/ê³¼ì—… ë²”ìœ„ | | | |\n"
                                "| ì£¼ìš” ê³¼ì—… ë‚´ìš© | | | |\n"
                                "| ìˆ˜í–‰ ì‹œ ì£¼ì˜ì‚¬í•­ | | | |\n"
                                "| ê¸°íƒ€ ë³€ê²½ì‚¬í•­ | | | |\n\n"
                                "[ì§ì „ ê³¼ì—…ì§€ì‹œì„œ]\n{prev_text}\n\n[ê¸ˆë…„ë„ ê³¼ì—…ì§€ì‹œì„œ]\n{curr_text}"
                            )
                            chain = compare_prompt | llm | StrOutputParser()
                            compare_res = invoke_with_retry(chain, {"prev_text": relevant_prev, "curr_text": relevant_current})
                            
                            st.subheader("ï¿½ ê³¼ì—…ì§€ì‹œì„œ ë³€ê²½ ì‚¬í•­ ë¹„êµ")
                            st.markdown(compare_res)
                            st.session_state.analysis_results[f"{tab_name} (ê³¼ì—… ë¹„êµ)"] = compare_res
                        except Exception as e:
                            st.error(f"{tab_name} ê³¼ì—… ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

        # =====================================================================
        # Tab 1: Keyword Insight
        # =====================================================================
        with tabs[0]:
            st.header("ğŸ“Š í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸")
            chart = create_word_chart(top_keywords)
            if chart: st.pyplot(chart)
            with st.spinner("í•µì‹¬ í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì—… ìš”ì•½ ì¤‘..."):
                try:
                    prompt = ChatPromptTemplate.from_template(
                        "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                        "ì•„ë˜ ì œì•ˆìš”ì²­ì„œì˜ ìƒìœ„ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
                        "| êµ¬ë¶„ | ë‚´ìš© |\n|---|---|\n"
                        "| ì‚¬ì—…ëª…(ì¶”ì •) | ... |\n"
                        "| ë°œì£¼ ê¸°ê´€(ì¶”ì •) | ... |\n"
                        "| í•µì‹¬ ì£¼ì œ | 1~2ë¬¸ì¥ ìš”ì•½ |\n"
                        "| ì£¼ìš” í‚¤ì›Œë“œ êµ°ì§‘ | ê´€ë ¨ í‚¤ì›Œë“œ ê·¸ë£¹í•‘ |\n"
                        "| ì‚¬ì—… ìœ í˜• | ì—°êµ¬ìš©ì—­/ì‹œìŠ¤í…œê°œë°œ/ì¡°ì‚¬ì‚¬ì—… ë“± |\n\n"
                        "í‘œ ì™¸ì— ë‹¤ë¥¸ í˜•ì‹(ë¶ˆë¦¿, ë²ˆí˜¸ ëª©ë¡ ë“±)ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. "
                        "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. í‚¤ì›Œë“œ: {keywords}"
                    )
                    chain = prompt | llm | StrOutputParser()
                    insight = invoke_with_retry(chain, {"keywords": str(top_keywords)})
                    insight = insight.replace("<br>", " ").replace("<br/>", " ")
                    st.markdown(insight)
                    st.session_state.analysis_results["í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸"] = f"Top Keywords: {str(top_keywords)}\n\n{insight}"
                except Exception as e:
                    st.error(f"í‚¤ì›Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        time.sleep(2)

        # =====================================================================
        # Tab 2: ì¡°ì‚¬/ë¶„ì„ ì„¤ê³„ (Categories 1 & 3 & 5)
        # =====================================================================
        run_comparison_analysis(
            "ğŸ”¬ ì¡°ì‚¬/ë¶„ì„ ì„¤ê³„",
            # Current analysis instructions (New List Categories)
            "ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì„¸ìš”:\n"
            "## 1. ì¡°ì‚¬ ì„¤ê³„ (Research Design)\n"
            "* ì¡°ì‚¬ ë°©ë²• (êµ¬ì²´ì  ë°©ì‹, ì˜¨/ì˜¤í”„ë¼ì¸ ë“±)\n"
            "* ì¡°ì‚¬ ëŒ€ìƒ ë° ë²”ìœ„ (ëª¨ì§‘ë‹¨ ì •ì˜, ìœ íš¨ í‘œë³¸ ìˆ˜)\n"
            "* ì¡°ì‚¬ ì§€ì—­\n\n"
            "## 3. ì¡°ì‚¬ ë‚´ìš© ë° ë„êµ¬ (Instruments)\n"
            "* ì„¤ë¬¸ì§€ êµ¬ì„± ìš”ê±´ (ì‹œê³„ì—´ ìœ ì§€, ì‹ ê·œ ê°œë°œ ë“±)\n"
            "* ì‚¬ì „ ì¡°ì‚¬(Pilot Test) ìš”ê±´\n"
            "* ì „ë¬¸ê°€ ìë¬¸ ë° ê²€í†  ìš”ê±´\n\n"
            "## 5. ë°ì´í„° ë¶„ì„ ë° í™œìš© (Analysis)\n"
            "* í•„ìˆ˜ ë¶„ì„ ê¸°ë²• (ë¹ˆë„/êµì°¨ ë¶„ì„, ê°€ì¤‘ì¹˜ ì‚°ì¶œ, ê³ ê¸‰ í†µê³„ ë“±)\n"
            "* ê²°ê³¼ í™œìš© ë°©ì•ˆ (ì¸í¬ê·¸ë˜í”½, ì •ì±… ì œì–¸ ë“±)",
            # Comparison instructions
            "ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ 'ì¡°ì‚¬ ì„¤ê³„' ë° 'ë¶„ì„ ìš”ê±´' ê´€ë ¨ ë³€ê²½ì‚¬í•­ì„ ë¹„êµí•˜ì„¸ìš”:\n\n"
            "| êµ¬ë¶„ | ì§ì „ ì—°ë„ | ê¸ˆë…„ë„ | ë¹„ê³  |\n|---|---|---|---|\n"
            "| ì¡°ì‚¬ ë°©ë²• | | | |\n"
            "| ì¡°ì‚¬ ëŒ€ìƒ/í‘œë³¸ | | | |\n"
            "| ì¡°ì‚¬ ë‚´ìš©/ì„¤ë¬¸ | | | |\n"
            "| ë¶„ì„ ë°©ë²• | | | |\n"
            "| ê²°ê³¼ í™œìš© | | | |\n",
            ["ì¡°ì‚¬ ê°œìš”", "ê³¼ì—… ë‚´ìš©", "ê³¼ì—… ëª©ì ", "ê³¼ì—… ë²”ìœ„", "ìˆ˜í–‰ ë‚´ìš©", "ì‚¬ì—… ëª©ì ", "ì‚¬ì—… ê°œìš”", "ì‚¬ì—… ê¸°ê°„", "ì‚¬ì—… ì˜ˆì‚°", "ì¡°ì‚¬ ëŒ€ìƒ", "ì¡°ì‚¬ ë°©ë²•", "ê³¼ì—… ìˆ˜í–‰", "ì„¸ë¶€ ê³¼ì—…", "ì—°êµ¬ ëª©ì ", "ìš©ì—­ ë‚´ìš©", "ë¶„ì„ ë°©ë²•", "í†µê³„"],
            full_current_text, prev_text, tabs[1]
        )

        # =====================================================================
        # Tab 3: í‘œë³¸/í’ˆì§ˆ ê´€ë¦¬ (Categories 2 & 4)
        # =====================================================================
        run_comparison_analysis(
            "ğŸ“ í‘œë³¸/í’ˆì§ˆ ê´€ë¦¬",
            # Current analysis instructions
            "ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì„¸ìš”:\n"
            "## 2. í‘œë³¸ ì„¤ê³„ (Sampling Design)\n"
            "* ëª¨ì§‘ë‹¨ ë° í‘œë³¸ì¶”ì¶œí‹€(Frame)\n"
            "* í‘œë³¸ ì¶”ì¶œ ë°©ë²• (ì¸µí™”/í• ë‹¹/ë¬´ì‘ìœ„ ë“± ìƒì„¸)\n"
            "* ì¸µí™” ê¸°ì¤€ ë° í• ë‹¹ í‘œ\n"
            "* í‘œë³¸ ì˜¤ì°¨ ë° ì‹ ë¢°ìˆ˜ì¤€\n\n"
            "## 4. ì‹¤ì‚¬ ìš´ì˜ ë° í’ˆì§ˆ ê´€ë¦¬ (Fieldwork & QC)\n"
            "* ì¡°ì‚¬ì› ìš´ìš© (ìê²© ìš”ê±´, êµìœ¡ í•„ìˆ˜ ì‚¬í•­)\n"
            "* ë°ì´í„° ê²€ì¦(Verification) ë¹„ìœ¨ ë° ë°©ë²• (Back-check ë“±)\n"
            "* ë°ì´í„° í´ë¦¬ë‹ (Logic Check) ë° ì´ìƒì¹˜ ì²˜ë¦¬\n"
            "* ì‘ë‹µë¥  ì œê³  ë°©ì•ˆ (ë‹µë¡€í’ˆ, ì½œë°± ê¸°ì¤€ ë“±)",
            # Comparison instructions
            "ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ 'í‘œë³¸ ì„¤ê³„' ë° 'ì‹¤ì‚¬ í’ˆì§ˆê´€ë¦¬' ê´€ë ¨ ë³€ê²½ì‚¬í•­ì„ ë¹„êµí•˜ì„¸ìš”:\n\n"
            "| êµ¬ë¶„ | ì§ì „ ì—°ë„ | ê¸ˆë…„ë„ | ë¹„ê³  |\n|---|---|---|---|\n"
            "| í‘œë³¸ ì¶”ì¶œ ë°©ë²• | | | |\n"
            "| ëª©í‘œ í‘œë³¸ ìˆ˜ | | | |\n"
            "| ì˜¤ì°¨/ì‹ ë¢° ìˆ˜ì¤€ | | | |\n"
            "| ì¡°ì‚¬ì› ìš”ê±´ | | | |\n"
            "| í’ˆì§ˆê´€ë¦¬/ê²€ì¦ | | | |\n",
            ["í‘œë³¸", "ëª¨ì§‘ë‹¨", "ì˜¤ì°¨", "ì‹ ë¢° ìˆ˜ì¤€", "ì¶”ì¶œ ë°©ë²•", "í• ë‹¹", "ì¸µí™”", "ê°€ì¤‘ì¹˜", "í‘œë³¸ í¬ê¸°", "í‘œë³¸ ì„¤ê³„", "ì¡°ì‚¬ ëŒ€ìƒ", "ì‘ë‹µì", "ì„¤ë¬¸", "ë©´ì ‘", "ì¡°ì‚¬ ì¸ì›", "ë¶„ì„ ë°©ë²•", "í’ˆì§ˆ", "ê²€ì¦", "ì—ë””íŒ…"],
            full_current_text, prev_text, tabs[2]
        )

        # =====================================================================
        # Tab 4: ì‚¬ì—… ê´€ë¦¬ (Category 6)
        # =====================================================================
        run_task_comparison_analysis(
            "ï¿½ ì‚¬ì—… ê´€ë¦¬",
            "ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì„¸ìš”:\n"
            "## 6. ì‚¬ì—… ê´€ë¦¬ ë° ë³´ê³  (Project Management)\n"
            "* ë³´ê³  ì£¼ê¸° ë° ì²´ê³„ (ì°©ìˆ˜/ì¤‘ê°„/ìµœì¢…/ìˆ˜ì‹œ)\n"
            "* ì¼ì • ê´€ë¦¬ (ê³„ì•½ì¼ ê¸°ì¤€ ì°©ìˆ˜ë³´ê³ , ì¤‘ê°„ë³´ê³  ì‹œê¸° ë“±)\n"
            "* ì¸ë ¥ ìš´ì˜ ë° ë³´ì•ˆ ê´€ë¦¬ ê³„íš\n\n"
            "## í•„ìˆ˜ ê³¼ì—… ë° ì„±ê³¼ë¬¼\n"
            "* í•„ìˆ˜ ìˆ˜í–‰ í™œë™ ìƒì„¸ ëª©ë¡\n"
            "* ìµœì¢… ë‚©í’ˆ ì„±ê³¼ë¬¼ ëª©ë¡ ë° í˜•íƒœ",
            ["ê³¼ì—… ì§€ì‹œ", "ê³¼ì—… ë‚´ìš©", "ìˆ˜í–‰ ì‚¬í•­", "ì£¼ì˜ ì‚¬í•­", "ìœ ì˜ ì‚¬í•­", "íŠ¹ì´ ì‚¬í•­", "ê³¼ì—… ë²”ìœ„", "ì œì•ˆ ìš”êµ¬", "ì„¸ë¶€ ê³¼ì—…", "ë³´ê³ ", "ì¼ì •", "ê´€ë¦¬"],
            full_current_text, prev_text, tabs[3]
        )

        # =====================================================================
        # Tab 5: ì¤€ë¹„ì„œë¥˜
        # =====================================================================
        run_analysis(
            "ğŸ“„ ì¤€ë¹„ì„œë¥˜",
            "ì œì•ˆìš”ì²­ì„œì—ì„œ ì…ì°° ì°¸ê°€ ìê²©ê³¼ ì œì¶œ ì„œë¥˜ë¥¼ ë©´ë°€íˆ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œë“¤ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
            "**[ì…ì°° ì°¸ê°€ ìê²© ìš”ê±´]**\n\n"
            "| ë²ˆí˜¸ | ìê²© ìš”ê±´ | ì„¸ë¶€ ì¡°ê±´ |\n|---|---|---|\n"
            "| 1 | | |\n\n"
            "**[ì œì¶œ ì„œë¥˜ ëª©ë¡]**\n\n"
            "| ë²ˆí˜¸ | ì„œë¥˜ëª… | ë¶€ìˆ˜ | ì œì¶œ í˜•ì‹ | ë¹„ê³  |\n|---|---|---|---|---|\n"
            "| 1 | | | | |\n\n"
            "**[ì…ì°° ì¼ì •]**\n\n"
            "| ì¼ì • í•­ëª© | ì¼ì‹œ | ì¥ì†Œ/ë°©ë²• |\n|---|---|---|\n"
            "| ì…ì°° ê³µê³ ì¼ | | |\n"
            "| ì œì•ˆì„œ ì œì¶œ ë§ˆê° | | |\n"
            "| ê¸°ìˆ  í‰ê°€ | | |\n"
            "| ë‚™ì°°ì ë°œí‘œ | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ì°¸ê°€ ìê²©", "ì œì¶œ ì„œë¥˜", "ì…ì°° ë³´ì¦ê¸ˆ", "ì‹¤ì  ì¦ëª…", "ì‚¬ì—…ì ë“±ë¡", "ì…ì°° ì¼ì •", "ì œì•ˆì„œ ì œì¶œ", "ì°¸ê°€ ë“±ë¡", "ì ê²© ì‹¬ì‚¬", "ì…ì°° ê³µê³ "],
            full_current_text, tabs[4]
        )

        # =====================================================================
        # Tab 6: ëª©ì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸
        # =====================================================================
        run_analysis(
            "âœ… ëª©ì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸",
            "ì œì•ˆìš”ì²­ì„œì— ì œì‹œëœ ì œì•ˆì„œ ëª©ì°¨ êµ¬ì„±ì´ë‚˜ í‰ê°€ í•­ëª©ì„ ë©´ë°€íˆ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
            "**[ì œì•ˆì„œ í‰ê°€ í•­ëª© ë° ë°°ì ]**\n\n"
            "| í‰ê°€ ì˜ì—­ | í‰ê°€ í•­ëª© | ë°°ì  | ì£¼ìš” í‰ê°€ ë‚´ìš© |\n|---|---|---|---|\n"
            "| | | | |\n\n"
            "**[ê¶Œì¥ ëª©ì°¨ êµ¬ì„±]**\n\n"
            "| ë²ˆí˜¸ | ëª©ì°¨ í•­ëª© | ëŒ€ì‘ í‰ê°€ í•­ëª© | ê¶Œì¥ ë¶„ëŸ‰ |\n|---|---|---|---|\n"
            "| 1 | | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ í‰ê°€ ê¸°ì¤€ê³¼ ë°°ì ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ì œì•ˆì„œ ëª©ì°¨", "í‰ê°€ í•­ëª©", "ë°°ì  í•œë„", "ì‘ì„± ì§€ì¹¨", "í‰ê°€ ê¸°ì¤€", "ê¸°ìˆ  í‰ê°€", "ë°°ì ", "í‰ê°€ ìœ„ì›", "ì‹¬ì‚¬ ê¸°ì¤€", "í‰ê°€í‘œ"],
            full_current_text, tabs[5]
        )

        # =====================================================================
        # Tab 7: ìƒì„¸ ì „ëµ
        # =====================================================================
        run_analysis(
            "ğŸ¯ ìƒì„¸ ì „ëµ",
            "ì œì•ˆìš”ì²­ì„œì—ì„œ ì œì•ˆ ì „ëµ ìˆ˜ë¦½ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ë©´ë°€íˆ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œë“¤ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
            "**[ì •ëŸ‰ í‰ê°€ ê¸°ì¤€]**\n\n"
            "| í‰ê°€ í•­ëª© | ê¸°ì¤€ | ë°°ì  | ë¹„ê³  |\n|---|---|---|---|\n"
            "| | | | |\n\n"
            "**[ìˆ˜í–‰ ì¸ë ¥ ìš”ê±´]**\n\n"
            "| êµ¬ë¶„ | ìê²© ìš”ê±´ | ì¸ì› | íˆ¬ì… ê¸°ê°„ | ë¹„ê³  |\n|---|---|---|---|---|\n"
            "| ì‚¬ì—…ì±…ì„ì(PM) | | | | |\n"
            "| ì—°êµ¬ì› | | | | |\n\n"
            "**[ë°ì´í„° í’ˆì§ˆ/ë³´ì•ˆ ìš”ê±´]**\n\n"
            "| êµ¬ë¶„ | ìš”êµ¬ì‚¬í•­ | ì„¸ë¶€ ë‚´ìš© |\n|---|---|---|\n"
            "| ë°ì´í„° í’ˆì§ˆ | | |\n"
            "| ë³´ì•ˆ ëŒ€ì±… | | |\n"
            "| ê°œì¸ì •ë³´ ë³´í˜¸ | | |\n\n"
            "**[ì‚¬í›„ ê´€ë¦¬/ìœ ì§€ë³´ìˆ˜]**\n\n"
            "| êµ¬ë¶„ | ë‚´ìš© | ê¸°ê°„ |\n|---|---|---|\n"
            "| í•˜ì ë³´ìˆ˜ | | |\n"
            "| ìœ ì§€ë³´ìˆ˜ | | |\n"
            "| ê¸°ìˆ  ì§€ì› | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ íŒ©íŠ¸ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ì •ëŸ‰ í‰ê°€", "ìˆ˜í–‰ ì¸ë ¥", "ì°¸ì—¬ ì¸ë ¥", "ë°ì´í„° í’ˆì§ˆ", "ë³´ì•ˆ ëŒ€ì±…", "ì‚¬í›„ ì§€ì›", "ìœ ì§€ ë³´ìˆ˜", "í•˜ì ë³´ìˆ˜", "ê°œì¸ì •ë³´", "ì¸ë ¥ ìê²©", "ì±…ì„ì", "ê¸°ìˆ  ì¸ë ¥"],
            full_current_text, tabs[6]
        )

        # Download Button
        st.markdown("---")
        import report_utils
        if st.session_state.analysis_results:
            docx_file = report_utils.generate_word_report(st.session_state.analysis_results)
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì›Œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=docx_file,
                file_name="win_strategy_report.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="primary",
                use_container_width=True
            )

    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

st.markdown('<div class="footer">Developed by ã…ˆã……ã… | Powered by Streamlit & Groq Llama3</div>', unsafe_allow_html=True)
