
import streamlit as st
import pdfplumber
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re
import os
from kiwipiepy import Kiwi
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import datetime
import time
import auth
import email_utils

# -----------------------------------------------------------------------------
# 1. Config & Branding
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ìˆ˜ì£¼ë¹„ì±… - RFP ë¶„ì„ ì†”ë£¨ì…˜",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem; font-weight: 800; text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.1rem; text-align: center; color: #888;
        margin-bottom: 1.5rem;
    }
    .footer {
        text-align: center; color: #aaa; font-size: 0.85rem;
        margin-top: 3rem; padding: 1rem 0;
        border-top: 1px solid #eee;
    }
    /* Sidebar login styling */
    .sidebar-login-header {
        font-size: 1.1rem; font-weight: 700; margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. Authentication (Sidebar)
# -----------------------------------------------------------------------------
auth.init_db()

if "user" not in st.session_state:
    st.session_state.user = None

# --- Sidebar ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2921/2921222.png", width=50)
    
    if st.session_state.user:
        # --- Logged-in state ---
        st.success(f"ğŸ‘¤ **{st.session_state.user['name']}**ë‹˜ ì ‘ì† ì¤‘")
        
        if not st.session_state.user.get('approved', False):
            st.warning("â³ ê³„ì • ìŠ¹ì¸ ëŒ€ê¸° ì¤‘")
        
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_sidebar", use_container_width=True):
            st.session_state.user = None
            st.rerun()
        
        # Admin Logic
        if st.session_state.user.get('role') == 'admin':
            st.markdown("---")
            st.subheader("ğŸ‘‘ ê´€ë¦¬ì ë©”ë‰´")
            pending_users = auth.get_pending_users()
            if not pending_users.empty:
                st.warning(f"ìŠ¹ì¸ ëŒ€ê¸°: {len(pending_users)}ëª…")
                for _, row in pending_users.iterrows():
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"**{row['name']}** ({row['email']})")
                    with col2:
                        if st.button("ìŠ¹ì¸", key=f"btn_{row['email']}"):
                            auth.approve_user(row['email'])
                            success, form = email_utils.send_approval_email(row['email'])
                            if success:
                                st.success(f"ìŠ¹ì¸ ì™„ë£Œ!")
                            else:
                                st.warning(f"ìŠ¹ì¸ ì™„ë£Œ, ë©”ì¼ ì‹¤íŒ¨")
                            st.rerun()
            else:
                st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ íšŒì› ì—†ìŒ")
    else:
        # --- Not logged-in state ---
        st.markdown('<div class="sidebar-login-header">ğŸ” ë¡œê·¸ì¸</div>', unsafe_allow_html=True)
        
        login_tab, signup_tab = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"])
        
        with login_tab:
            email = st.text_input("ì´ë©”ì¼", key="login_email")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")
            if st.button("ë¡œê·¸ì¸", type="primary", use_container_width=True):
                user = auth.login_user(email, password)
                if user:
                    st.session_state.user = user
                    st.rerun()
                else:
                    st.error("ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with signup_tab:
            new_email = st.text_input("ì´ë©”ì¼", key="signup_email")
            new_name = st.text_input("ì´ë¦„", key="signup_name")
            new_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="signup_pw")
            new_password_confirm = st.text_input("ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="signup_pw_chk")
            
            if st.button("ê°€ì…í•˜ê¸°", use_container_width=True):
                if new_password != new_password_confirm:
                    st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                elif not new_email or not new_password or not new_name:
                    st.error("ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    if auth.create_user(new_email, new_password, new_name):
                        email_utils.send_admin_notification(new_email, new_name)
                        st.success("ê°€ì… ìš”ì²­ ì™„ë£Œ! ê´€ë¦¬ì ìŠ¹ì¸ í›„ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    else:
                        st.error("ì´ë¯¸ ê°€ì…ëœ ì´ë©”ì¼ì…ë‹ˆë‹¤.")
    
    # Settings
    st.markdown("---")
    api_key = st.secrets.get("groq", {}).get("api_key", "")
    if not api_key:
        api_key = os.environ.get("GROQ_API_KEY", "")
    
    st.markdown("---")
    st.markdown("**Developed by ã…ˆã……ã…**")

# -----------------------------------------------------------------------------
# 3. Utility Functions
# -----------------------------------------------------------------------------
def mask_pii(text):
    rrn_pattern = r'\d{6}[-\s]\d{7}'
    masked_text = re.sub(rrn_pattern, '******-*******', text)
    return masked_text

def extract_text_from_pdf(uploaded_file):
    text = ""
    try:
        with pdfplumber.open(uploaded_file) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        return f"Error reading PDF: {e}"
    return mask_pii(text)

def analyze_keywords(text):
    kiwi = Kiwi()
    tokens = kiwi.tokenize(text[:200000])
    nouns = [token.form for token in tokens if token.tag.startswith('NN') and len(token.form) > 1]
    stopwords = ['ëŒ€í•œ', 'ê´€ë ¨', 'ìœ„í•´', 'ê²½ìš°', 'ì‚¬í•­', 'ì´ìƒ', 'ì´í•˜', 'ê¸°íƒ€', 'í¬í•¨', 'ìˆ˜í–‰', 'ì‘ì„±', 'ì œì¶œ', 'í•´ë‹¹']
    nouns = [n for n in nouns if n not in stopwords]
    count = Counter(nouns)
    return count.most_common(20)

def create_word_chart(keywords):
    if not keywords: return None
    words, counts = zip(*keywords)
    fig, ax = plt.subplots(figsize=(10, 6))
    import platform
    import matplotlib.font_manager as fm
    
    system_name = platform.system()
    if system_name == 'Windows':
        plt.rc('font', family='Malgun Gothic')
    elif system_name == 'Darwin':
        plt.rc('font', family='AppleGothic')
    else:
        paths = [
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf'
        ]
        font_name = None
        for path in paths:
            if os.path.exists(path):
                font_name = fm.FontProperties(fname=path).get_name()
                break
        if font_name:
            plt.rc('font', family=font_name)
        else:
            plt.rc('font', family='NanumGothic')
    
    plt.rc('axes', unicode_minus=False)
    ax.barh(words, counts, color='#3B82F6')
    ax.invert_yaxis()
    ax.set_xlabel('ë¹ˆë„ìˆ˜')
    ax.set_title('ìƒìœ„ 20ê°œ í•µì‹¬ í‚¤ì›Œë“œ')
    return fig

def get_relevant_context(text, keywords, box_size=2000, max_len=4000):
    """Extracts relevant text chunks around keywords. Sizes reduced for Groq TPM limit."""
    relevant_chunks = []
    text_lower = text.lower()
    for kw in keywords:
        start_idx = 0
        while True:
            idx = text_lower.find(kw, start_idx)
            if idx == -1: break
            start = max(0, idx - 500)
            end = min(len(text), idx + box_size)
            chunk = text[start:end]
            relevant_chunks.append(chunk)
            start_idx = idx + len(kw)
    if not relevant_chunks:
        return text[:max_len]
    combined = "\n...\n".join(relevant_chunks)
    return combined[:max_len]

# -----------------------------------------------------------------------------
# 4. Main Content (Always visible)
# -----------------------------------------------------------------------------
st.markdown('<div class="main-header">ìˆ˜ì£¼ë¹„ì±… (Win Strategy)</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ê³µê³µê¸°ê´€ ì…ì°° ì„±ê³µì„ ìœ„í•œ ì œì•ˆìš”ì²­ì„œ(RFP) ì‹¬ì¸µ ë¶„ì„ ì†”ë£¨ì…˜</div>', unsafe_allow_html=True)

# Rate limit retry helper
def invoke_with_retry(chain, params, max_retries=3):
    """Invoke LLM chain with retry on rate limit errors."""
    for attempt in range(max_retries):
        try:
            return chain.invoke(params)
        except Exception as e:
            error_str = str(e)
            if 'rate_limit' in error_str.lower() or '413' in error_str or '429' in error_str:
                wait_time = 15 * (attempt + 1)
                time.sleep(wait_time)
            else:
                raise e
    raise Exception("API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

st.info("âš ï¸ ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ëª¨ë“  ë¬¸ì„œëŠ” **PDF í˜•ì‹**ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

col1, col2 = st.columns(2)
with col1:
    st.subheader("1. ê¸ˆë…„ë„ ê³µê³  ìë£Œ (í•„ìˆ˜)")
    st.markdown("<div style='margin-bottom: 28px;'></div>", unsafe_allow_html=True)
    current_rfp = st.file_uploader("ì˜¬í•´ ì œì•ˆìš”ì²­ì„œ ì—…ë¡œë“œ", type=["pdf"], key="curr_rfp")
    no_task_desc = st.checkbox("ê³¼ì—…ì§€ì‹œì„œ ì—†ìŒ (ì œì•ˆìš”ì²­ì„œ ë‚´ í¬í•¨)", key="chk_no_task")
    current_task = st.file_uploader("ì˜¬í•´ ê³¼ì—…ì§€ì‹œì„œ ì—…ë¡œë“œ", type=["pdf"], disabled=no_task_desc, key="curr_task")

with col2:
    st.subheader("2. ì§ì „ ì—°ë„ ê³µê³  ìë£Œ (ì„ íƒ)")
    no_prev_rfp = st.checkbox("ì§ì „ ì œì•ˆìš”ì²­ì„œ ì—†ìŒ", key="chk_no_prev_rfp")
    prev_rfp = st.file_uploader("ì§ì „ ì—°ë„ ì œì•ˆìš”ì²­ì„œ ì—…ë¡œë“œ", type=["pdf"], disabled=no_prev_rfp, key="prev_rfp")
    no_prev_task = st.checkbox("ì§ì „ ê³¼ì—…ì§€ì‹œì„œ ì—†ìŒ", key="chk_no_prev_task")
    prev_task = st.file_uploader("ì§ì „ ì—°ë„ ê³¼ì—…ì§€ì‹œì„œ ì—…ë¡œë“œ", type=["pdf"], disabled=no_prev_task, key="prev_task")

# --- Conditional: Show analysis button only for logged-in & approved users ---
is_logged_in = st.session_state.user is not None
is_approved = is_logged_in and st.session_state.user.get('approved', False)

if not is_logged_in:
    st.warning("ğŸ”’ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•˜ë ¤ë©´ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ **ë¡œê·¸ì¸**í•´ ì£¼ì„¸ìš”.")
    start_analysis = False
elif not is_approved:
    st.warning("â³ ê³„ì • ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    start_analysis = False
else:
    start_analysis = st.button("ì œì•ˆìš”ì²­ì„œ ë¶„ì„ ì‹œì‘ ğŸš€", type="primary", use_container_width=True)

# -----------------------------------------------------------------------------
# 5. Analysis Logic (only for approved users)
# -----------------------------------------------------------------------------
if start_analysis:
    if not api_key:
        st.error("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ API Key ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    if not current_rfp:
        st.error("ì˜¬í•´ ì œì•ˆìš”ì²­ì„œëŠ” í•„ìˆ˜ ì—…ë¡œë“œ í•­ëª©ì…ë‹ˆë‹¤.")
        st.stop()

    with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        curr_rfp_text = extract_text_from_pdf(current_rfp)
        curr_task_text = ""
        if not no_task_desc and current_task:
            curr_task_text = extract_text_from_pdf(current_task)
        full_current_text = curr_rfp_text + "\n" + curr_task_text
        
        prev_text = ""
        if not no_prev_rfp and prev_rfp:
            prev_text += extract_text_from_pdf(prev_rfp) + "\n"
        if not no_prev_task and prev_task:
            prev_text += extract_text_from_pdf(prev_task)
        
        top_keywords = analyze_keywords(full_current_text)

    st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    try:
        MODEL_NAME = "llama-3.3-70b-versatile"
        llm = ChatGroq(temperature=0.0, model=MODEL_NAME, api_key=api_key)

        has_prev = bool(prev_text.strip())

        tabs = st.tabs(["ğŸ“Š í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸", " ì¡°ì‚¬ì„¤ê³„", "ğŸ“ í‘œë³¸ì„¤ê³„", "ğŸ“‹ í•„ìˆ˜ ì œì•ˆ í•­ëª©", "ğŸ“„ ì¤€ë¹„ì„œë¥˜", "âœ… ëª©ì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸", "ğŸ¯ ìƒì„¸ ì „ëµ"])
        
        if "analysis_results" not in st.session_state:
            st.session_state.analysis_results = {}

        # =====================================================================
        # Common: run_analysis (no comparison)
        # =====================================================================
        def run_analysis(tab_name, instructions, keywords, context_text, target_tab):
            with target_tab:
                st.header(tab_name)
                relevant_text = get_relevant_context(context_text, keywords)
                with st.spinner(f"{tab_name} ë¶„ì„ ì¤‘..."):
                    try:
                        time.sleep(10)
                        sys_prompt = (
                            "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ë° ì œì•ˆìš”ì²­ì„œ(RFP) ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                            "ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:\n"
                            "1. ë¬¸ì„œì— ìˆëŠ” 'ì‚¬ì‹¤(Fact)'ë§Œì„ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬í•˜ì„¸ìš”.\n"
                            "2. ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë„êµ¬, ê¸°ìˆ , ë°©ë²•ë¡ , ì˜ê²¬ì€ ì ˆëŒ€ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                            "3. ë‚´ìš©ì´ ì—†ìœ¼ë©´ 'í•´ë‹¹ ë‚´ìš© ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\n"
                            "4. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ(table) í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. í‘œ ì™¸ì— ë¶ˆë¦¿ ëª©ë¡ì´ë‚˜ í…ìŠ¤íŠ¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                            "5. HTML íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³  ë§ˆí¬ë‹¤ìš´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                            "6. ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ 'í•œêµ­ì–´'ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n"
                            "7. ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´, ì•„ëì–´ê°€ ì ˆëŒ€ í¬í•¨ë˜ì§€ ì•Šê²Œ í•˜ì„¸ìš”.\n"
                            "8. ë°œì£¼ê¸°ê´€ë§ˆë‹¤ ìš©ì–´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ìš©ì–´ëŠ” ê°™ì€ í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. "
                            "ì˜ˆ: 'ê³¼ì—…ë²”ìœ„'='ì‚¬ì—…ë²”ìœ„'='ìˆ˜í–‰ë²”ìœ„', 'ëª¨ì§‘ë‹¨'='ì¡°ì‚¬ëŒ€ìƒ', 'ì‚¬ì—…ë¹„'='ì˜ˆì‚°'='ìš©ì—­ë¹„' ë“±\n\n"
                            f"[ë¶„ì„ ì§€ì‹œì‚¬í•­]\n{instructions}"
                        )
                        prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
                        chain = prompt | llm | StrOutputParser()
                        response = invoke_with_retry(chain, {"text": relevant_text})
                        response = response.replace("<br>", " ").replace("<br/>", " ")
                        st.markdown(response)
                        st.session_state.analysis_results[tab_name] = response
                    except Exception as e:
                        st.error(f"{tab_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # =====================================================================
        # Common: run_comparison_analysis (Condition: Prev exists -> Only Compare, Else -> Single Analysis)
        # =====================================================================
        def run_comparison_analysis(tab_name, instructions_current, instructions_compare, keywords, current_text, previous_text, target_tab):
            """If prev doc exists, ONLY show comparison. Else, show current analysis."""
            with target_tab:
                st.header(tab_name)
                relevant_current = get_relevant_context(current_text, keywords)

                # CASE 1: Previous document exists -> Comparison Analysis ONLY
                if previous_text.strip():
                    relevant_prev = get_relevant_context(previous_text, keywords)
                    with st.spinner(f"{tab_name} - ì§ì „ ì—°ë„ ëŒ€ë¹„ ë¹„êµ ë¶„ì„ ì¤‘..."):
                        try:
                            time.sleep(15)
                            compare_prompt = ChatPromptTemplate.from_template(
                                "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ë° ì œì•ˆìš”ì²­ì„œ(RFP) ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                                "ì•„ë˜ì˜ [ì§ì „ ì—°ë„ ë¬¸ì„œ]ì™€ [ê¸ˆë…„ë„ ë¬¸ì„œ]ë¥¼ ë¹„êµ ë¶„ì„í•˜ì„¸ìš”.\n\n"
                                "**í•µì‹¬ ê·œì¹™:**\n"
                                "- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. í‘œ ì™¸ì— ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                                "- ë°œì£¼ê¸°ê´€ë§ˆë‹¤ ê°™ì€ ê°œë…ì„ ë‹¤ë¥¸ ìš©ì–´ë¡œ ë¶€ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                                "ì˜ë¯¸ê°€ ìœ ì‚¬í•œ í•­ëª©ì€ ê°™ì€ í–‰ì—ì„œ ë¹„êµí•˜ì„¸ìš”. "
                                "ì˜ˆ: 'ê³¼ì—…ë²”ìœ„'ì™€ 'ì‚¬ì—…ë²”ìœ„', 'ëª¨ì§‘ë‹¨'ê³¼ 'ì¡°ì‚¬ëŒ€ìƒ', 'ì‚¬ì—…ë¹„'ì™€ 'ì˜ˆì‚°' ë“±\n"
                                "- 'ë¹„ê³ ' ì—´ì—ëŠ” ë³€ê²½ëœ ë‚´ìš©ì´ ìˆ˜ì£¼ ì „ëµì— ì–´ë–¤ ì˜ë¯¸ì¸ì§€ í•œ ì¤„ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.\n"
                                "- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n\n"
                                f"{instructions_compare}\n\n"
                                "[ì§ì „ ì—°ë„ ë¬¸ì„œ]\n{prev_text}\n\n[ê¸ˆë…„ë„ ë¬¸ì„œ]\n{curr_text}"
                            )
                            chain = compare_prompt | llm | StrOutputParser()
                            compare_res = invoke_with_retry(chain, {"prev_text": relevant_prev, "curr_text": relevant_current})
                            compare_res = compare_res.replace("<br>", " ").replace("<br/>", " ")
                            st.subheader("ğŸ”„ ì§ì „ ì—°ë„ ëŒ€ë¹„ ë³€ê²½ ì‚¬í•­")
                            st.markdown(compare_res)
                            st.session_state.analysis_results[f"{tab_name} (ë¹„êµ)"] = compare_res
                        except Exception as e:
                            st.error(f"{tab_name} ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

                # CASE 2: No previous document -> Single Year Analysis
                else:
                    with st.spinner(f"{tab_name} - ê¸ˆë…„ë„ ë¶„ì„ ì¤‘..."):
                        try:
                            time.sleep(10)
                            sys_prompt = (
                                "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ë° ì œì•ˆìš”ì²­ì„œ(RFP) ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                                "ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:\n"
                                "1. ë¬¸ì„œì— ìˆëŠ” 'ì‚¬ì‹¤(Fact)'ë§Œì„ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬í•˜ì„¸ìš”.\n"
                                "2. ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë„êµ¬, ê¸°ìˆ , ë°©ë²•ë¡ , ì˜ê²¬ì€ ì ˆëŒ€ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                                "3. ë‚´ìš©ì´ ì—†ìœ¼ë©´ 'í•´ë‹¹ ë‚´ìš© ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\n"
                                "4. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ(table) í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. í‘œ ì™¸ì— ë¶ˆë¦¿ ëª©ë¡ì´ë‚˜ í…ìŠ¤íŠ¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
                                "5. HTML íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³  ë§ˆí¬ë‹¤ìš´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                                "6. ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ 'í•œêµ­ì–´'ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n"
                                "7. ë°œì£¼ê¸°ê´€ë§ˆë‹¤ ìš©ì–´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ìš©ì–´ëŠ” ê°™ì€ í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n\n"
                                f"[ë¶„ì„ ì§€ì‹œì‚¬í•­]\n{instructions_current}"
                            )
                            prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
                            chain = prompt | llm | StrOutputParser()
                            response = invoke_with_retry(chain, {"text": relevant_current})
                            response = response.replace("<br>", " ").replace("<br/>", " ")
                            st.subheader("ğŸ“Œ ê¸ˆë…„ë„ ë¶„ì„ ê²°ê³¼")
                            st.markdown(response)
                            st.session_state.analysis_results[tab_name] = response
                        except Exception as e:
                            st.error(f"{tab_name} ê¸ˆë…„ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                            return

        # =====================================================================
        # Common: run_task_comparison_analysis (Specific for Tab 4 - Task Description)
        # =====================================================================
        def run_task_comparison_analysis(tab_name, instructions_current, keywords, current_text, previous_text, target_tab):
            """Specific comparison for Task Description (Scope, Content, Cautions)."""
            with target_tab:
                st.header(tab_name)
                relevant_current = get_relevant_context(current_text, keywords)
                
                # Check if previous task description exists
                has_prev_task = bool(previous_text.strip())

                if has_prev_task:
                    relevant_prev = get_relevant_context(previous_text, keywords)
                    with st.spinner(f"{tab_name} - ê³¼ì—…ì§€ì‹œì„œ ë¹„êµ ë¶„ì„ ì¤‘..."):
                        try:
                            time.sleep(15)
                            compare_prompt = ChatPromptTemplate.from_template(
                                "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ë° ê³¼ì—…ì§€ì‹œì„œ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                                "ì•„ë˜ [ì§ì „ ê³¼ì—…ì§€ì‹œì„œ]ì™€ [ê¸ˆë…„ë„ ê³¼ì—…ì§€ì‹œì„œ]ë¥¼ ë¹„êµí•˜ì—¬,\n"
                                "**ì¡°ì‚¬ ë²”ìœ„, ê³¼ì—… ë‚´ìš©, ì£¼ì˜ì‚¬í•­(íŠ¹ì´ì‚¬í•­)** ì¸¡ë©´ì—ì„œ ë³€ê²½ëœ ë‚´ìš©ì„ ë¶„ì„í•˜ì„¸ìš”.\n\n"
                                "**í•µì‹¬ ê·œì¹™:**\n"
                                "- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                                "- 'ë¹„ê³ ' ì—´ì—ëŠ” ë³€ê²½ì‚¬í•­ì´ ì œì•ˆì„œ ì‘ì„± ì‹œ ìœ ì˜í•´ì•¼ í•  ì ì„ ê¸°ìˆ í•˜ì„¸ìš”.\n"
                                "- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n\n"
                                "**[ë¹„êµ í•­ëª©]**\n"
                                "| êµ¬ë¶„ | ì§ì „ ê³¼ì—…ì§€ì‹œì„œ | ê¸ˆë…„ë„ ê³¼ì—…ì§€ì‹œì„œ | ë¹„ê³ (ì œì•ˆ ì „ëµ) |\n"
                                "|---|---|---|---|\n"
                                "| ì¡°ì‚¬/ê³¼ì—… ë²”ìœ„ | | | |\n"
                                "| ì£¼ìš” ê³¼ì—… ë‚´ìš© | | | |\n"
                                "| ìˆ˜í–‰ ì‹œ ì£¼ì˜ì‚¬í•­ | | | |\n"
                                "| ê¸°íƒ€ ë³€ê²½ì‚¬í•­ | | | |\n\n"
                                "[ì§ì „ ê³¼ì—…ì§€ì‹œì„œ]\n{prev_text}\n\n[ê¸ˆë…„ë„ ê³¼ì—…ì§€ì‹œì„œ]\n{curr_text}"
                            )
                            chain = compare_prompt | llm | StrOutputParser()
                            compare_res = invoke_with_retry(chain, {"prev_text": relevant_prev, "curr_text": relevant_current})
                            compare_res = compare_res.replace("<br>", " ").replace("<br/>", " ")
                            st.subheader("ğŸ”„ ê³¼ì—…ì§€ì‹œì„œ ë³€ê²½ ì‚¬í•­ ë¹„êµ")
                            st.markdown(compare_res)
                            st.session_state.analysis_results[f"{tab_name} (ê³¼ì—… ë¹„êµ)"] = compare_res
                        except Exception as e:
                            st.error(f"{tab_name} ê³¼ì—… ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                else:
                    # Fallback to single analysis if no prev task decription
                    with st.spinner(f"{tab_name} - ê¸ˆë…„ë„ ê³¼ì—… ë¶„ì„ ì¤‘..."):
                        try:
                            time.sleep(10)
                            sys_prompt = (
                                "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ë° ì œì•ˆìš”ì²­ì„œ(RFP) ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
                                "ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”:\n"
                                "1. ë¬¸ì„œì— ìˆëŠ” 'ì‚¬ì‹¤(Fact)'ë§Œì„ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬í•˜ì„¸ìš”.\n"
                                "2. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ(table) í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                                f"[ë¶„ì„ ì§€ì‹œì‚¬í•­]\n{instructions_current}"
                            )
                            prompt = ChatPromptTemplate.from_messages([("system", sys_prompt), ("user", "{text}")])
                            chain = prompt | llm | StrOutputParser()
                            response = invoke_with_retry(chain, {"text": relevant_current})
                            response = response.replace("<br>", " ").replace("<br/>", " ")
                            st.subheader("ğŸ“Œ ê¸ˆë…„ë„ ë¶„ì„ ê²°ê³¼")
                            st.markdown(response)
                            st.session_state.analysis_results[tab_name] = response
                        except Exception as e:
                            st.error(f"{tab_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

        # =====================================================================
        # Tab 1: Keyword Insight
        # =====================================================================
        with tabs[0]:
            st.header("ğŸ“Š í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸")
            chart = create_word_chart(top_keywords)
            if chart: st.pyplot(chart)
            with st.spinner("í•µì‹¬ í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì—… ìš”ì•½ ì¤‘..."):
                try:
                    prompt = ChatPromptTemplate.from_template(
                        "ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì…ì°° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                        "ì•„ë˜ ì œì•ˆìš”ì²­ì„œì˜ ìƒìœ„ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
                        "| êµ¬ë¶„ | ë‚´ìš© |\n|---|---|\n"
                        "| ì‚¬ì—…ëª…(ì¶”ì •) | ... |\n"
                        "| ë°œì£¼ ê¸°ê´€(ì¶”ì •) | ... |\n"
                        "| í•µì‹¬ ì£¼ì œ | 1~2ë¬¸ì¥ ìš”ì•½ |\n"
                        "| ì£¼ìš” í‚¤ì›Œë“œ êµ°ì§‘ | ê´€ë ¨ í‚¤ì›Œë“œ ê·¸ë£¹í•‘ |\n"
                        "| ì‚¬ì—… ìœ í˜• | ì—°êµ¬ìš©ì—­/ì‹œìŠ¤í…œê°œë°œ/ì¡°ì‚¬ì‚¬ì—… ë“± |\n\n"
                        "í‘œ ì™¸ì— ë‹¤ë¥¸ í˜•ì‹(ë¶ˆë¦¿, ë²ˆí˜¸ ëª©ë¡ ë“±)ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. "
                        "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. í‚¤ì›Œë“œ: {keywords}"
                    )
                    chain = prompt | llm | StrOutputParser()
                    insight = invoke_with_retry(chain, {"keywords": str(top_keywords)})
                    insight = insight.replace("<br>", " ").replace("<br/>", " ")
                    st.markdown(insight)
                    st.session_state.analysis_results["í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸"] = f"Top Keywords: {str(top_keywords)}\n\n{insight}"
                except Exception as e:
                    st.error(f"í‚¤ì›Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

        time.sleep(5)

        # =====================================================================
        # Tab 2: ì¡°ì‚¬ì„¤ê³„ (with comparison if prev docs available)
        # =====================================================================
        run_comparison_analysis(
            "ğŸ”¬ ì¡°ì‚¬ì„¤ê³„",
            # Current analysis instructions
            "ì œì•ˆìš”ì²­ì„œì—ì„œ ì¡°ì‚¬ì„¤ê³„ ë° ê³¼ì—… ë‚´ìš©ì„ ë©´ë°€íˆ ê²€í† í•˜ì—¬ ì•„ë˜ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n"
            "ë¬¸ì„œ ì „ì²´ë¥¼ ê¼¼ê¼¼íˆ ì½ê³ , ê³¼ì—…ì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ê¹Œì§€ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
            "| êµ¬ë¶„ | ë‚´ìš© |\n|---|---|\n"
            "| ì‚¬ì—…ëª… | |\n"
            "| ì‚¬ì—… ëª©ì  | |\n"
            "| ì‚¬ì—… ë°°ê²½ | |\n"
            "| ì‚¬ì—… ê¸°ê°„ | |\n"
            "| ì‚¬ì—… ì˜ˆì‚°(ë¶€ê°€ì„¸ í¬í•¨ ì—¬ë¶€) | |\n"
            "| ë°œì£¼ ê¸°ê´€ | |\n"
            "| ê³„ì•½ ë°©ì‹(ì´ì•¡/ë‹¨ê°€ ë“±) | |\n"
            "| ì¡°ì‚¬ ëŒ€ìƒ/ëª¨ì§‘ë‹¨ | |\n"
            "| ì¡°ì‚¬ ì§€ì—­/ë²”ìœ„ | |\n"
            "| ì¡°ì‚¬ ë°©ë²•(ì •ëŸ‰/ì •ì„±/í˜¼í•©) | |\n"
            "| ì¡°ì‚¬ ë„êµ¬(ì„¤ë¬¸/ë©´ì ‘/ê´€ì°° ë“±) | |\n"
            "| ì£¼ìš” ê³¼ì—… ë‚´ìš© (ì„¸ë¶€ ë‚˜ì—´) | |\n"
            "| ê³¼ì—… ìˆ˜í–‰ ì ˆì°¨/ë‹¨ê³„ | |\n"
            "| ì˜ˆë¹„ì¡°ì‚¬/ì‚¬ì „ì¡°ì‚¬ ì—¬ë¶€ | |\n"
            "| ìë¬¸ìœ„ì›íšŒ/ì „ë¬¸ê°€ ê²€í†  ìš”ê±´ | |\n"
            "| ì¤‘ê°„ë³´ê³ /ìµœì¢…ë³´ê³  ì‹œê¸° | |\n"
            "| ë‚©í’ˆ ì„±ê³¼ë¬¼ ëª©ë¡ | |\n"
            "| ê¸°íƒ€ íŠ¹ì´ì‚¬í•­/ìœ ì˜ì‚¬í•­ | |\n\n"
            "'ì£¼ìš” ê³¼ì—… ë‚´ìš©' í•­ëª©ì€ ë¬¸ì„œì— ê¸°ìˆ ëœ ì„¸ë¶€ ê³¼ì—…ì„ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ëª¨ë‘ ë‚˜ì—´í•˜ì„¸ìš”.\n"
            "ê° í•­ëª©ì€ ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            # Comparison instructions
            "ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ ì§ì „ ì—°ë„ì™€ ê¸ˆë…„ë„ì˜ ì¡°ì‚¬ì„¤ê³„ ê´€ë ¨ í•­ëª©ì„ ë¹„êµí•˜ì„¸ìš”:\n\n"
            "| ë¹„êµ í•­ëª© | ì§ì „ ì—°ë„ | ê¸ˆë…„ë„ | ë¹„ê³  |\n|---|---|---|---|\n"
            "| ì‚¬ì—… ëª©ì  | | | |\n"
            "| ì‚¬ì—… ê¸°ê°„ | | | |\n"
            "| ì‚¬ì—… ì˜ˆì‚° | | | |\n"
            "| ì¡°ì‚¬ ëŒ€ìƒ/ë²”ìœ„ | | | |\n"
            "| ì¡°ì‚¬ ë°©ë²• | | | |\n"
            "| ì£¼ìš” ê³¼ì—… ë‚´ìš© ë³€ê²½ì  | | | |\n"
            "| ë‚©í’ˆ ì„±ê³¼ë¬¼ ë³€ê²½ì  | | | |\n"
            "| ê¸°íƒ€ ë³€ê²½ ì‚¬í•­ | | | |\n\n"
            "'ë¹„ê³ ' ì—´ì—ëŠ” ë³€ê²½ì´ ìˆ˜ì£¼ ì „ëµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í•œ ì¤„ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.\n"
            "ë³€ê²½ì´ ì—†ìœ¼ë©´ 'ë³€ê²½ ì—†ìŒ', í•´ë‹¹ í•­ëª©ì´ ì—†ìœ¼ë©´ 'ëª…ì‹œ ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.",
            ["ì¡°ì‚¬ ê°œìš”", "ê³¼ì—… ë‚´ìš©", "ê³¼ì—… ëª©ì ", "ê³¼ì—… ë²”ìœ„", "ìˆ˜í–‰ ë‚´ìš©", "ì‚¬ì—… ëª©ì ", "ì‚¬ì—… ê°œìš”", "ì‚¬ì—… ê¸°ê°„", "ì‚¬ì—… ì˜ˆì‚°", "ì¡°ì‚¬ ëŒ€ìƒ", "ì¡°ì‚¬ ë°©ë²•", "ê³¼ì—… ìˆ˜í–‰", "ì„¸ë¶€ ê³¼ì—…", "ì—°êµ¬ ëª©ì ", "ìš©ì—­ ë‚´ìš©"],
            full_current_text, prev_text, tabs[1]
        )

        # =====================================================================
        # Tab 3: í‘œë³¸ì„¤ê³„ (with comparison if prev docs available)
        # =====================================================================
        run_comparison_analysis(
            "ğŸ“ í‘œë³¸ì„¤ê³„",
            # Current analysis instructions
            "ì œì•ˆìš”ì²­ì„œì—ì„œ í‘œë³¸ì„¤ê³„ ê´€ë ¨ ë‚´ìš©ì„ ë©´ë°€íˆ ê²€í† í•˜ì—¬ ì•„ë˜ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n"
            "ìˆ˜ì¹˜, ë¹„ìœ¨, êµ¬ì²´ì  ê¸°ì¤€ì„ ê°€ëŠ¥í•œ í•œ ë¬¸ì„œ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
            "| êµ¬ë¶„ | ë‚´ìš© |\n|---|---|\n"
            "| ì¡°ì‚¬ ëŒ€ìƒ(ëª¨ì§‘ë‹¨) ì •ì˜ | |\n"
            "| ì¡°ì‚¬ ëŒ€ìƒ ì—°ë ¹/ì„±ë³„/ì§€ì—­ ë²”ìœ„ | |\n"
            "| ëª©í‘œ í‘œë³¸ í¬ê¸°(ì´ ìˆ˜) | |\n"
            "| í‘œë³¸ ì¶”ì¶œ ë°©ë²•(í™•ë¥ /ë¹„í™•ë¥ /í• ë‹¹ ë“±) | |\n"
            "| ì¸µí™” ê¸°ì¤€(ì§€ì—­/ì„±ë³„/ì—°ë ¹ ë“±) | |\n"
            "| ì„¸ë¶€ í• ë‹¹ ê¸°ì¤€ ë° ë¹„ìœ¨ | |\n"
            "| í‘œë³¸ ì˜¤ì°¨ í•œê³„ | |\n"
            "| ì‹ ë¢° ìˆ˜ì¤€ | |\n"
            "| ê°€ì¤‘ì¹˜ ì‚°ì¶œ/ì ìš© ë°©ë²• | |\n"
            "| ì¡°ì‚¬ ë„êµ¬(ì„¤ë¬¸ì§€/ë©´ì ‘ì§€ ë“±) | |\n"
            "| ì¡°ì‚¬ ë°©ë²•(ì˜¨ë¼ì¸/ëŒ€ë©´/ì „í™” ë“±) | |\n"
            "| ì¡°ì‚¬ ê¸°ê°„ | |\n"
            "| ë°ì´í„° í´ë¦¬ë‹/ê²€ì¦ ì ˆì°¨ | |\n"
            "| ë¶„ì„ ë°©ë²•(í†µê³„ê¸°ë²• ë“±) | |\n"
            "| ê¸°íƒ€ íŠ¹ì´ì‚¬í•­ | |\n\n"
            "ê° í•­ëª©ì€ ë¬¸ì„œì— ëª…ì‹œëœ ìˆ˜ì¹˜ì™€ ë°©ë²•ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            # Comparison instructions
            "ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ ì§ì „ ì—°ë„ì™€ ê¸ˆë…„ë„ì˜ í‘œë³¸ì„¤ê³„ ê´€ë ¨ í•­ëª©ì„ ë¹„êµí•˜ì„¸ìš”:\n\n"
            "| ë¹„êµ í•­ëª© | ì§ì „ ì—°ë„ | ê¸ˆë…„ë„ | ë¹„ê³  |\n|---|---|---|---|\n"
            "| ì¡°ì‚¬ ëŒ€ìƒ(ëª¨ì§‘ë‹¨) | | | |\n"
            "| í‘œë³¸ í¬ê¸° | | | |\n"
            "| í‘œë³¸ ì¶”ì¶œ ë°©ë²• | | | |\n"
            "| ì¸µí™”/í• ë‹¹ ê¸°ì¤€ | | | |\n"
            "| ì˜¤ì°¨/ì‹ ë¢° ìˆ˜ì¤€ | | | |\n"
            "| ì¡°ì‚¬ ë°©ë²• | | | |\n"
            "| ì¡°ì‚¬ ê¸°ê°„ | | | |\n"
            "| ë¶„ì„ ë°©ë²• | | | |\n"
            "| ê¸°íƒ€ ë³€ê²½ ì‚¬í•­ | | | |\n\n"
            "'ë¹„ê³ ' ì—´ì—ëŠ” ë³€ê²½ì´ í‘œë³¸ í’ˆì§ˆì´ë‚˜ ìˆ˜ì£¼ ì „ëµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í•œ ì¤„ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.\n"
            "ë³€ê²½ì´ ì—†ìœ¼ë©´ 'ë³€ê²½ ì—†ìŒ', í•´ë‹¹ í•­ëª©ì´ ì—†ìœ¼ë©´ 'ëª…ì‹œ ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.",
            ["í‘œë³¸", "ëª¨ì§‘ë‹¨", "ì˜¤ì°¨", "ì‹ ë¢° ìˆ˜ì¤€", "ì¶”ì¶œ ë°©ë²•", "í• ë‹¹", "ì¸µí™”", "ê°€ì¤‘ì¹˜", "í‘œë³¸ í¬ê¸°", "í‘œë³¸ ì„¤ê³„", "ì¡°ì‚¬ ëŒ€ìƒ", "ì‘ë‹µì", "ì„¤ë¬¸", "ë©´ì ‘", "ì¡°ì‚¬ ì¸ì›", "ë¶„ì„ ë°©ë²•"],
            full_current_text, prev_text, tabs[2]
        )

        # =====================================================================
        # Tab 4: í•„ìˆ˜ ì œì•ˆ í•­ëª© (Task Description Comparison)
        # =====================================================================
        run_task_comparison_analysis(
            "ğŸ“‹ í•„ìˆ˜ ì œì•ˆ í•­ëª©",
            "ì œì•ˆìš”ì²­ì„œì— ëª…ì‹œëœ í•„ìˆ˜ ìˆ˜í–‰ í™œë™ê³¼ ì„±ê³¼í’ˆì„ ë©´ë°€íˆ ê²€í† í•˜ì—¬ ì•„ë˜ í‘œë“¤ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n"
            "ê³¼ì—… ë‚´ìš©ì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­, ë°œì£¼ì²˜ê°€ ë°˜ë“œì‹œ í¬í•¨í•˜ë¼ê³  ëª…ì‹œí•œ í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”.\n\n"
            "**[í•„ìˆ˜ ìˆ˜í–‰ í™œë™]**\n\n"
            "| ë²ˆí˜¸ | ìˆ˜í–‰ í™œë™ | ì„¸ë¶€ ë‚´ìš© | ë¹„ê³  |\n|---|---|---|---|\n"
            "| 1 | | | |\n\n"
            "**[ë‚©í’ˆ ì„±ê³¼ë¬¼]**\n\n"
            "| ë²ˆí˜¸ | ì„±ê³¼ë¬¼ ëª…ì¹­ | ê·œê²©/í˜•ì‹ | ìˆ˜ëŸ‰ | ì œì¶œ ì‹œê¸° |\n|---|---|---|---|---|\n"
            "| 1 | | | | |\n\n"
            "**[ë³´ê³  ì²´ê³„]**\n\n"
            "| ë³´ê³  ìœ í˜• | ì‹œê¸° | ë‚´ìš© | ë¹„ê³  |\n|---|---|---|---|\n"
            "| ì°©ìˆ˜ë³´ê³  | | | |\n"
            "| ì¤‘ê°„ë³´ê³  | | | |\n"
            "| ìµœì¢…ë³´ê³  | | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ê³¼ì—… ì§€ì‹œ", "ê³¼ì—… ë‚´ìš©", "ìˆ˜í–‰ ì‚¬í•­", "ì£¼ì˜ ì‚¬í•­", "ìœ ì˜ ì‚¬í•­", "íŠ¹ì´ ì‚¬í•­", "ê³¼ì—… ë²”ìœ„", "ì œì•ˆ ìš”êµ¬", "ì„¸ë¶€ ê³¼ì—…"],
            full_current_text, prev_text, tabs[3]
        )

        # =====================================================================
        # Tab 5: ì¤€ë¹„ì„œë¥˜
        # =====================================================================
        run_analysis(
            "ğŸ“„ ì¤€ë¹„ì„œë¥˜",
            "ì œì•ˆìš”ì²­ì„œì—ì„œ ì…ì°° ì°¸ê°€ ìê²©ê³¼ ì œì¶œ ì„œë¥˜ë¥¼ ë©´ë°€íˆ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œë“¤ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
            "**[ì…ì°° ì°¸ê°€ ìê²© ìš”ê±´]**\n\n"
            "| ë²ˆí˜¸ | ìê²© ìš”ê±´ | ì„¸ë¶€ ì¡°ê±´ |\n|---|---|---|\n"
            "| 1 | | |\n\n"
            "**[ì œì¶œ ì„œë¥˜ ëª©ë¡]**\n\n"
            "| ë²ˆí˜¸ | ì„œë¥˜ëª… | ë¶€ìˆ˜ | ì œì¶œ í˜•ì‹ | ë¹„ê³  |\n|---|---|---|---|---|\n"
            "| 1 | | | | |\n\n"
            "**[ì…ì°° ì¼ì •]**\n\n"
            "| ì¼ì • í•­ëª© | ì¼ì‹œ | ì¥ì†Œ/ë°©ë²• |\n|---|---|---|\n"
            "| ì…ì°° ê³µê³ ì¼ | | |\n"
            "| ì œì•ˆì„œ ì œì¶œ ë§ˆê° | | |\n"
            "| ê¸°ìˆ  í‰ê°€ | | |\n"
            "| ë‚™ì°°ì ë°œí‘œ | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ì°¸ê°€ ìê²©", "ì œì¶œ ì„œë¥˜", "ì…ì°° ë³´ì¦ê¸ˆ", "ì‹¤ì  ì¦ëª…", "ì‚¬ì—…ì ë“±ë¡", "ì…ì°° ì¼ì •", "ì œì•ˆì„œ ì œì¶œ", "ì°¸ê°€ ë“±ë¡", "ì ê²© ì‹¬ì‚¬", "ì…ì°° ê³µê³ "],
            full_current_text, tabs[4]
        )

        # =====================================================================
        # Tab 6: ëª©ì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸
        # =====================================================================
        run_analysis(
            "âœ… ëª©ì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸",
            "ì œì•ˆìš”ì²­ì„œì— ì œì‹œëœ ì œì•ˆì„œ ëª©ì°¨ êµ¬ì„±ì´ë‚˜ í‰ê°€ í•­ëª©ì„ ë©´ë°€íˆ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
            "**[ì œì•ˆì„œ í‰ê°€ í•­ëª© ë° ë°°ì ]**\n\n"
            "| í‰ê°€ ì˜ì—­ | í‰ê°€ í•­ëª© | ë°°ì  | ì£¼ìš” í‰ê°€ ë‚´ìš© |\n|---|---|---|---|\n"
            "| | | | |\n\n"
            "**[ê¶Œì¥ ëª©ì°¨ êµ¬ì„±]**\n\n"
            "| ë²ˆí˜¸ | ëª©ì°¨ í•­ëª© | ëŒ€ì‘ í‰ê°€ í•­ëª© | ê¶Œì¥ ë¶„ëŸ‰ |\n|---|---|---|---|\n"
            "| 1 | | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ í‰ê°€ ê¸°ì¤€ê³¼ ë°°ì ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ì œì•ˆì„œ ëª©ì°¨", "í‰ê°€ í•­ëª©", "ë°°ì  í•œë„", "ì‘ì„± ì§€ì¹¨", "í‰ê°€ ê¸°ì¤€", "ê¸°ìˆ  í‰ê°€", "ë°°ì ", "í‰ê°€ ìœ„ì›", "ì‹¬ì‚¬ ê¸°ì¤€", "í‰ê°€í‘œ"],
            full_current_text, tabs[5]
        )

        # =====================================================================
        # Tab 7: ìƒì„¸ ì „ëµ
        # =====================================================================
        run_analysis(
            "ğŸ¯ ìƒì„¸ ì „ëµ",
            "ì œì•ˆìš”ì²­ì„œì—ì„œ ì œì•ˆ ì „ëµ ìˆ˜ë¦½ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ë©´ë°€íˆ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ í‘œë“¤ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n\n"
            "**[ì •ëŸ‰ í‰ê°€ ê¸°ì¤€]**\n\n"
            "| í‰ê°€ í•­ëª© | ê¸°ì¤€ | ë°°ì  | ë¹„ê³  |\n|---|---|---|---|\n"
            "| | | | |\n\n"
            "**[ìˆ˜í–‰ ì¸ë ¥ ìš”ê±´]**\n\n"
            "| êµ¬ë¶„ | ìê²© ìš”ê±´ | ì¸ì› | íˆ¬ì… ê¸°ê°„ | ë¹„ê³  |\n|---|---|---|---|---|\n"
            "| ì‚¬ì—…ì±…ì„ì(PM) | | | | |\n"
            "| ì—°êµ¬ì› | | | | |\n\n"
            "**[ë°ì´í„° í’ˆì§ˆ/ë³´ì•ˆ ìš”ê±´]**\n\n"
            "| êµ¬ë¶„ | ìš”êµ¬ì‚¬í•­ | ì„¸ë¶€ ë‚´ìš© |\n|---|---|---|\n"
            "| ë°ì´í„° í’ˆì§ˆ | | |\n"
            "| ë³´ì•ˆ ëŒ€ì±… | | |\n"
            "| ê°œì¸ì •ë³´ ë³´í˜¸ | | |\n\n"
            "**[ì‚¬í›„ ê´€ë¦¬/ìœ ì§€ë³´ìˆ˜]**\n\n"
            "| êµ¬ë¶„ | ë‚´ìš© | ê¸°ê°„ |\n|---|---|---|\n"
            "| í•˜ì ë³´ìˆ˜ | | |\n"
            "| ìœ ì§€ë³´ìˆ˜ | | |\n"
            "| ê¸°ìˆ  ì§€ì› | | |\n\n"
            "ë¬¸ì„œì— ëª…ì‹œëœ íŒ©íŠ¸ë§Œ ê¸°ì¬í•˜ì„¸ìš”.",
            ["ì •ëŸ‰ í‰ê°€", "ìˆ˜í–‰ ì¸ë ¥", "ì°¸ì—¬ ì¸ë ¥", "ë°ì´í„° í’ˆì§ˆ", "ë³´ì•ˆ ëŒ€ì±…", "ì‚¬í›„ ì§€ì›", "ìœ ì§€ ë³´ìˆ˜", "í•˜ì ë³´ìˆ˜", "ê°œì¸ì •ë³´", "ì¸ë ¥ ìê²©", "ì±…ì„ì", "ê¸°ìˆ  ì¸ë ¥"],
            full_current_text, tabs[6]
        )

        # Download Button
        st.markdown("---")
        import report_utils
        if st.session_state.analysis_results:
            docx_file = report_utils.generate_word_report(st.session_state.analysis_results)
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì›Œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=docx_file,
                file_name="win_strategy_report.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="primary",
                use_container_width=True
            )

    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

st.markdown('<div class="footer">Developed by ã…ˆã……ã… | Powered by Streamlit & Groq Llama3</div>', unsafe_allow_html=True)
